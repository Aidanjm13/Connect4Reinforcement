{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP1z7GIGl1ve"
      },
      "source": [
        "# Reinforcement Learning with Convolutional Neural Network\n",
        "\n",
        "This notebook demonstrates a basic Deep Q-Network (DQN) style reinforcement learning setup with a convolutional neural network (CNN) as the Q-function approximator.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## General Considerations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ⚠️ Run this notebook **locally**, not in Colab. Audio processing with `ffmpeg` does **not** work in Colab. Additionally, the models and metrics routing is based on the repo relative locations, so make sure to **clone** the Repo\n",
        "\n",
        "1. Clone this repo.\n",
        "2. Install dependencies, including `ffmpeg`:\n",
        "   ```bash\n",
        "   brew install ffmpeg  # for macOS\n",
        "   ```\n",
        "3. Open the notebook locally. Set `TRAIN_MODEL = True` to retrain, or `False` to use the provided model (in `/models/`) and metrics (in `/metrics/`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_MODEL = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just check weather `ffmpeg` is installed or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"FFmpeg not found!\" # else install it using e.g. brew install ffmpeg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'which' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!which ffmpeg || echo \"FFmpeg not found!\" # else install it using e.g. brew install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duSA10BUl7Hf"
      },
      "source": [
        "## 1. Setup and Imports\n",
        "\n",
        "Import necessary libraries and set up the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aJpypK1Al-Hw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "import random\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import time\n",
        "import io\n",
        "import re\n",
        "import tempfile\n",
        "from contextlib import suppress\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGdR_jidmC_7"
      },
      "source": [
        "Device configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXnfMDVrmEcV",
        "outputId": "cdb44bc2-74f1-40e1-bdc8-a2914d802d3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXELUdhbmGRF"
      },
      "source": [
        "## 2. Define the Convolutional Q-Network\n",
        "\n",
        "The heart of our agent is the Q-network: a small Convolution Neural Network that takes the board state (a 6×7 grid) as input and outputs one Q-value per possible action (each of the 7 columns). Convolutions let the network detect spatial patterns—like three pieces in a row—so it can learn which board layouts are promising."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RmPtrlkUmNgg"
      },
      "outputs": [],
      "source": [
        "class ConvQNetwork(nn.Module):\n",
        "    def __init__(self, input_shape=(1,6,7), num_actions=7):\n",
        "        super().__init__()\n",
        "        c, h, w = input_shape\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(c, 32, kernel_size=(3,3), stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=(3,3), stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        conv_out_size = self._get_conv_out(input_shape)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(conv_out_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_actions)\n",
        "        )\n",
        "\n",
        "    def _get_conv_out(self, shape):\n",
        "        o = self.conv(torch.zeros(1, *shape))\n",
        "        return int(np.prod(o.size()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv_out = self.conv(x).view(x.size(0), -1)\n",
        "        return self.fc(conv_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN0370nprBZR"
      },
      "source": [
        "# Define Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need a simple Connect 4 environment that:\n",
        "\n",
        "1. Tracks the board state.\n",
        "\n",
        "2. Checks for valid moves.\n",
        "\n",
        "3. Applies a move and returns the new state, reward, and whether the game ended.\n",
        "\n",
        "This class will let our agent play full games and learn from each experience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2vgtT1NDrAEy"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "class BoardEnv(gym.Env):\n",
        "\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Observation: 6×7 matrix with values in {-1, 0, +1}\n",
        "        self.observation_space = spaces.Box(low=-1, high=1, shape=(6,7), dtype=np.int8)\n",
        "        # Actions: drop in one of 7 columns\n",
        "        self.action_space = spaces.Discrete(7)\n",
        "\n",
        "        self.state = {}\n",
        "        self.current_player = +1\n",
        "\n",
        "    def reset(self):\n",
        "        board = np.zeros((6,7), dtype=np.int8)\n",
        "        self.state[\"board\"] = board\n",
        "        self.state[\"move-sequence\"] = \"\"\n",
        "        self.current_player = +1\n",
        "        # Return a fresh copy for safety:\n",
        "        return {\"board\": board.copy(),\n",
        "                \"move-sequence\": self.state[\"move-sequence\"]}\n",
        "\n",
        "    def _get_action_reward(self, sequence, action):\n",
        "      scores = [0] * 7\n",
        "      # GET request\n",
        "      response = requests.get('https://ludolab.net/solve/connect4?position=' + sequence)\n",
        "      for score in response.json():\n",
        "          scores[int(score['move'])-1] = score['score']\n",
        "      return (scores[action]+20)/40\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        action: integer 0–6, the column to drop your piece into.\n",
        "        Returns: (next_state, reward, done, info)\n",
        "        \"\"\"\n",
        "        # 1) Check legality\n",
        "        if not self._is_valid_action(action):\n",
        "            # Illegal move: immediate loss\n",
        "            return {\"board\": self.state[\"board\"].copy(), \"move-sequence\": self.state[\"move-sequence\"]}, -1.0, True, {\"illegal_move\": True}\n",
        "\n",
        "        # 2) Apply move\n",
        "        row = self._get_drop_row(action)\n",
        "        self.state[\"board\"][row, action] = self.current_player\n",
        "        reward = self._get_action_reward(self.state[\"move-sequence\"], action)\n",
        "        self.state[\"move-sequence\"] += str(action+1)\n",
        "\n",
        "        # 3) Check for win\n",
        "        if self._check_win(self.state[\"board\"], action, self.current_player):\n",
        "            return {\"board\": self.state[\"board\"].copy(), \"move-sequence\": self.state[\"move-sequence\"]}, reward, True, {}\n",
        "\n",
        "        # 4) Check for draw\n",
        "        if np.all(self.state[\"board\"] != 0):\n",
        "            return {\"board\": self.state[\"board\"].copy(), \"move-sequence\": self.state[\"move-sequence\"]}, reward, True, {\"draw\": True}\n",
        "\n",
        "        # 5) Otherwise, game continues\n",
        "        self.current_player *= -1\n",
        "        return {\"board\": self.state[\"board\"].copy(), \"move-sequence\": self.state[\"move-sequence\"]}, reward, False, {}\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        # Simple text render\n",
        "        print(self.state[\"board\"])\n",
        "\n",
        "    def _is_valid_action(self, action):\n",
        "        return 0 <= action < 7 and self.state[\"board\"][0, action] == 0\n",
        "\n",
        "    def _get_drop_row(self, action):\n",
        "        # Find the lowest empty row in the chosen column\n",
        "        col = self.state[\"board\"][:, action]\n",
        "        empties = np.where(col == 0)[0]\n",
        "        return empties[-1]\n",
        "\n",
        "    def _check_win(self, board: np.ndarray, action: int, player: int) -> bool:\n",
        "      \"\"\"\n",
        "      Check for a four-in-a-row involving the most recent move in column `action`\n",
        "      by `player` (±1). Returns True if that move created a win.\n",
        "      \"\"\"\n",
        "      rows, cols = board.shape\n",
        "\n",
        "      # 1) Find the row index where the last piece landed\n",
        "      col_vals = board[:, action]\n",
        "      # indices where the board equals the player in that column\n",
        "      player_positions = np.where(col_vals == player)[0]\n",
        "      row = player_positions[0]\n",
        "\n",
        "      # 2) Define a helper to count in one direction\n",
        "      def count_dir(dr: int, dc: int) -> int:\n",
        "          r, c = row + dr, action + dc\n",
        "          count = 0\n",
        "          while 0 <= r < rows and 0 <= c < cols and board[r, c] == player:\n",
        "              count += 1\n",
        "              r += dr\n",
        "              c += dc\n",
        "          return count\n",
        "\n",
        "      # 3) Check horizontal (← & →)\n",
        "      horiz = 1 + count_dir(0, -1) + count_dir(0, +1)\n",
        "      if horiz >= 4:\n",
        "          return True\n",
        "\n",
        "      # 4) Check vertical\n",
        "      vert = 1 + count_dir(1, 0) + count_dir(-1, 0)\n",
        "      if vert >= 4:\n",
        "          return True\n",
        "\n",
        "      # 5) Check diagonal up-right / down-left\n",
        "      diag1 = 1 + count_dir(-1, +1) + count_dir(+1, -1)\n",
        "      if diag1 >= 4:\n",
        "          return True\n",
        "\n",
        "      # 6) Check diagonal up-left / down-right\n",
        "      diag2 = 1 + count_dir(-1, -1) + count_dir(+1, +1)\n",
        "      if diag2 >= 4:\n",
        "          return True\n",
        "\n",
        "      return False\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WudQm_cumhxC"
      },
      "source": [
        "## 3. Replay Buffer\n",
        "\n",
        "In Q-learning, it’s important to break correlations between consecutive moves. A replay buffer stores many past experiences (state, action, reward, next state, done) and later samples random batches from it. This helps stabilize training by smoothing out the learning updates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "78DGmKS3mjPw"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "        states, actions, rewards, next_states, dones = zip(*batch)\n",
        "        return (\n",
        "            np.stack(states),\n",
        "            np.array(actions),\n",
        "            np.array(rewards, dtype=np.float32),\n",
        "            np.stack(next_states),\n",
        "            np.array(dones, dtype=np.uint8)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INs43yakpVkD"
      },
      "source": [
        "## Illegal Moves Mask Helper\n",
        "\n",
        "Some board positions are invalid (e.g., a full column). This helper function builds a “mask” that marks illegal moves with very low Q-values so the agent never picks them. It ensures our agent only considers legal, realistic plays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5N3SRXiMpYmq"
      },
      "outputs": [],
      "source": [
        "def get_illegal_moves_mask(state):\n",
        "    \"\"\"\n",
        "    Given a board state (6×7 numpy array with 0=empty, ±1=player tokens),\n",
        "    return a boolean list of length 7 where True indicates the column is full/illegal.\n",
        "    \"\"\"\n",
        "    mask = [False] * 7\n",
        "    # Top row index 0 corresponds to the highest (first-placed) slot in each column\n",
        "    for col in range(7):\n",
        "        if state[0, col] != 0:\n",
        "            mask[col] = True\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8cOLXthqjik"
      },
      "source": [
        "# Epsilon Decay Helper\n",
        "\n",
        "To balance exploration vs. exploitation, we use an epsilon-greedy strategy: with probability ε the agent picks a random move (“explore”), and with probability 1 – ε it picks the best-known move (“exploit”). Over time, ε decays from a high value (more exploration early on) to a low value (more exploitation later)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "68WbAkYiqmn2"
      },
      "outputs": [],
      "source": [
        "def get_epsilon(start, end, period, step):\n",
        "    # linearly anneal from start → end over decay_steps\n",
        "    fraction = min(step / period, 1.0)\n",
        "    return start + fraction * (end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHgy4oaWmqaa"
      },
      "source": [
        "## 4. Training Loop\n",
        "\n",
        "This section runs the actual learning:\n",
        "\n",
        "1. Reset the environment to start a new game.\n",
        "\n",
        "2. Let the agent select moves, step through the environment, and store experiences.\n",
        "\n",
        "3. Periodically sample from the replay buffer to update the Q-network with gradient descent.\n",
        "\n",
        "4. Track performance metrics (e.g., win rate, loss rate, average reward) over many episodes.\n",
        "\n",
        "You’ll see the agent improve as training proceeds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nil7zA0Xmr5s",
        "outputId": "d6b4e214-c61c-4881-93fa-d6df2b518ce5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "if TRAIN_MODEL == True:\n",
        "  # create a log directory\n",
        "  log_dir = f\"logs/c4_dqn\"\n",
        "  checkpoint_dir = f\"checkpoints/c4_dqn\"\n",
        "  os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "  os.makedirs(log_dir, exist_ok=True)\n",
        "  checkpoint_period = 100\n",
        "\n",
        "  render_boards = True\n",
        "\n",
        "  # instantiate the writer\n",
        "  writer = SummaryWriter(log_dir)\n",
        "  print(f\"Logging to: {log_dir}\")\n",
        "\n",
        "  # Hyperparameters\n",
        "  learning_rate = 1e-4\n",
        "  gamma = 0.995\n",
        "  buffer_capacity = 10000\n",
        "  batch_size = 32\n",
        "  sync_target_steps = 2000\n",
        "  num_episodes = 2000\n",
        "  reward_decay = 0.03\n",
        "  epsilon_period = 20000\n",
        "\n",
        "  env = BoardEnv()\n",
        "\n",
        "  # Initialize networks and optimizer\n",
        "  policy_net1 = ConvQNetwork(input_shape=(1, 6, 7), num_actions=7).to(device)\n",
        "  target_net1 = ConvQNetwork(input_shape=(1, 6, 7), num_actions=7).to(device)\n",
        "  target_net1.load_state_dict(policy_net1.state_dict())\n",
        "  optimizer1 = optim.Adam(policy_net1.parameters(), lr=learning_rate)\n",
        "  replay_buffer1 = ReplayBuffer(buffer_capacity)\n",
        "\n",
        "  policy_net2 = ConvQNetwork(input_shape=(1, 6, 7), num_actions=7).to(device)\n",
        "  target_net2 = ConvQNetwork(input_shape=(1, 6, 7), num_actions=7).to(device)\n",
        "  target_net2.load_state_dict(policy_net2.state_dict())\n",
        "  optimizer2 = optim.Adam(policy_net2.parameters(), lr=learning_rate)\n",
        "  replay_buffer2 = ReplayBuffer(buffer_capacity)\n",
        "\n",
        "  steps_done = 0\n",
        "\n",
        "\n",
        "  for episode in range(num_episodes):\n",
        "      state = env.reset()  # obtain initial state\n",
        "      done = False\n",
        "      total_reward1 = 0\n",
        "      total_reward2 = 0\n",
        "      turns = 0\n",
        "\n",
        "      loss1Val = 0\n",
        "      loss2Val = 0\n",
        "\n",
        "      epsilon = get_epsilon(1.0, 0.05, epsilon_period, steps_done)\n",
        "\n",
        "      while not done:\n",
        "          # Select action (epsilon-greedy with action masking)\n",
        "          # Convert current board to tensor\n",
        "          state_tensor = torch.tensor(state[\"board\"], dtype=torch.float32, device=device).unsqueeze(0).unsqueeze(1)  # shape [1,1,6,7]\n",
        "          with torch.no_grad():\n",
        "              qvals = policy_net1(state_tensor)  # shape [1,7]\n",
        "              # Mask out illegal moves (e.g., full columns)\n",
        "              illegal_mask = get_illegal_moves_mask(state[\"board\"])  # bool array of length 7\n",
        "              qvals[0][illegal_mask] = -1e9\n",
        "              # Epsilon-greedy selection among legal actions\n",
        "              if random.random() < epsilon:\n",
        "                  valid_actions = [a for a, illegal in enumerate(illegal_mask) if not illegal]\n",
        "                  action = random.choice(valid_actions)\n",
        "              else:\n",
        "                  action = qvals.argmax(dim=1).item()\n",
        "          # Step environment\n",
        "          try:\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "          except:\n",
        "            action = -1\n",
        "            break\n",
        "\n",
        "          # Reward decay as the game progresses\n",
        "          reward = reward * (1 - reward_decay * turns)\n",
        "\n",
        "\n",
        "          # Compute placeholder reward\n",
        "          total_reward1 += reward\n",
        "\n",
        "          # Store transition\n",
        "          replay_buffer1.push(state[\"board\"], action, reward, next_state[\"board\"], done)\n",
        "\n",
        "          state = next_state\n",
        "\n",
        "          if not done:\n",
        "            #Model2 turn\n",
        "            with torch.no_grad():\n",
        "                qvals = policy_net2(state_tensor)  # shape [1,7]\n",
        "                # Mask out illegal moves (e.g., full columns)\n",
        "                illegal_mask = get_illegal_moves_mask(state[\"board\"])  # bool array of length 7\n",
        "                qvals[0][illegal_mask] = -1e9\n",
        "                # Epsilon-greedy selection among legal actions\n",
        "                if random.random() < epsilon:\n",
        "                    valid_actions = [a for a, illegal in enumerate(illegal_mask) if not illegal]\n",
        "                    action = random.choice(valid_actions)\n",
        "                else:\n",
        "                    action = qvals.argmax(dim=1).item()\n",
        "            # Step environment\n",
        "            try:\n",
        "              next_state, reward, done, _ = env.step(action)\n",
        "            except:\n",
        "              action = -1\n",
        "              break\n",
        "\n",
        "            # Reward decay as the game progresses\n",
        "            reward = reward * (1 - reward_decay * turns)\n",
        "\n",
        "            # Compute placeholder reward\n",
        "            total_reward2 += reward\n",
        "\n",
        "            # Store transition\n",
        "            replay_buffer2.push(state[\"board\"], action, reward, next_state[\"board\"], done)\n",
        "\n",
        "          steps_done += 1\n",
        "\n",
        "          if done and episode % 10 == 0 and render_boards:\n",
        "            env.render()\n",
        "\n",
        "          # Sample and learn\n",
        "          if len(replay_buffer1) >= batch_size:\n",
        "            # 1) Sample a batch\n",
        "            states_b, actions_b, rewards_b, next_states_b, dones_b = replay_buffer1.sample(batch_size)\n",
        "\n",
        "            # 2) Convert to tensors\n",
        "            states_v      = torch.tensor(states_b,      dtype=torch.float32, device=device).unsqueeze(1)   # [B,1,6,7]\n",
        "            actions_v     = torch.tensor(actions_b,     dtype=torch.int64,   device=device).unsqueeze(1)   # [B,1]\n",
        "            rewards_v     = torch.tensor(rewards_b,     dtype=torch.float32, device=device)               # [B]\n",
        "            next_states_v = torch.tensor(next_states_b, dtype=torch.float32, device=device).unsqueeze(1)   # [B,1,6,7]\n",
        "            dones_v       = torch.tensor(dones_b,       dtype=torch.uint8,   device=device)               # [B]\n",
        "\n",
        "            # 3) Compute current Q-values\n",
        "            q_vals = policy_net1(states_v).gather(1, actions_v).squeeze(1)        # [B]\n",
        "\n",
        "            # 4) Compute target Q-values\n",
        "            with torch.no_grad():\n",
        "                # max over next actions (masking illegal moves if desired)\n",
        "                next_q = target_net1(next_states_v).max(1)[0]                     # [B]\n",
        "                target_q = rewards_v + gamma * next_q * (1 - dones_v.float())   # [B]\n",
        "\n",
        "            # 5) Compute loss & backpropagate\n",
        "            loss1 = nn.MSELoss()(q_vals, target_q)\n",
        "\n",
        "            optimizer1.zero_grad()\n",
        "            loss1.backward()\n",
        "            optimizer1.step()\n",
        "            loss1Val = loss1.item()\n",
        "\n",
        "          # Sample and learn\n",
        "          if len(replay_buffer2) >= batch_size:\n",
        "            # 1) Sample a batch\n",
        "            states_b, actions_b, rewards_b, next_states_b, dones_b = replay_buffer2.sample(batch_size)\n",
        "\n",
        "            # 2) Convert to tensors\n",
        "            states_v      = torch.tensor(states_b,      dtype=torch.float32, device=device).unsqueeze(1)   # [B,1,6,7]\n",
        "            actions_v     = torch.tensor(actions_b,     dtype=torch.int64,   device=device).unsqueeze(1)   # [B,1]\n",
        "            rewards_v     = torch.tensor(rewards_b,     dtype=torch.float32, device=device)               # [B]\n",
        "            next_states_v = torch.tensor(next_states_b, dtype=torch.float32, device=device).unsqueeze(1)   # [B,1,6,7]\n",
        "            dones_v       = torch.tensor(dones_b,       dtype=torch.uint8,   device=device)               # [B]\n",
        "\n",
        "            # 3) Compute current Q-values\n",
        "            q_vals = policy_net2(states_v).gather(1, actions_v).squeeze(1)        # [B]\n",
        "\n",
        "            # 4) Compute target Q-values\n",
        "            with torch.no_grad():\n",
        "                # max over next actions (masking illegal moves if desired)\n",
        "                next_q = target_net2(next_states_v).max(1)[0]                     # [B]\n",
        "                target_q = rewards_v + gamma * next_q * (1 - dones_v.float())   # [B]\n",
        "\n",
        "            # 5) Compute loss & backpropagate\n",
        "            loss2 = nn.MSELoss()(q_vals, target_q)\n",
        "\n",
        "            optimizer2.zero_grad()\n",
        "            loss2.backward()\n",
        "            optimizer2.step()\n",
        "            loss2Val = loss2.item()\n",
        "\n",
        "            # Periodically sync target network\n",
        "            if steps_done % sync_target_steps == 0:\n",
        "                target_net1.load_state_dict(policy_net1.state_dict())\n",
        "                target_net2.load_state_dict(policy_net2.state_dict())\n",
        "\n",
        "      writer.add_scalar(\"Rewards/Agent1\", total_reward1, episode)\n",
        "      writer.add_scalar(\"Rewards/Agent2\", total_reward2, episode)\n",
        "\n",
        "      writer.add_scalar(\"Loss/Agent1\", loss1Val, episode)\n",
        "      writer.add_scalar(\"Loss/Agent2\", loss2Val, episode)\n",
        "\n",
        "      writer.add_scalar(\"Epsilon\", epsilon, episode)\n",
        "\n",
        "      print(f\"Episode {episode} - R1: {total_reward1} - R2: {total_reward2} - E: {epsilon} - A {action}\")\n",
        "\n",
        "      if episode % checkpoint_period == 0:\n",
        "        torch.save(policy_net1.state_dict(),\n",
        "                  f\"checkpoints/c4_dqn/policy_net1_ep{episode:04d}.pth\")\n",
        "        torch.save(policy_net2.state_dict(),\n",
        "                  f\"checkpoints/c4_dqn/policy_net2_ep{episode:04d}.pth\")\n",
        "        print(f\"  → Saved models at episode {episode}\")\n",
        "  episode += 1\n",
        "  torch.save(policy_net1.state_dict(),\n",
        "            f\"checkpoints/c4_dqn/Player1_Final.pth\")\n",
        "  torch.save(policy_net2.state_dict(),\n",
        "            f\"checkpoints/c4_dqn/Player2_Final.pth\")\n",
        "  print(f\"  → Saved models at episode {episode}\")\n",
        "  writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## UI Class\n",
        "\n",
        "To make interacting with our trained agent easy, we build a small user interface class:\n",
        "\n",
        "- It draws the current board.\n",
        "\n",
        "- Allows a human to click columns.\n",
        "\n",
        "- Lets you watch the model play against itself or a human.\n",
        "\n",
        "This turns our code into a playable Connect 4 game"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Connect4UI:\n",
        "    def __init__(self, model_p1, model_p2, ai_player=-1):\n",
        "        # Initialize the game environment\n",
        "        self.env = BoardEnv()\n",
        "        self.model_p1 = model_p1  # Model for player 1 (X)\n",
        "        self.model_p2 = model_p2  # Model for player -1 (O)\n",
        "        self.ai_player = ai_player  # -1 means AI plays as O, 1 means AI plays as X\n",
        "        self.model = self.model_p2 if ai_player == -1 else self.model_p1  # Current model\n",
        "\n",
        "        # Initialize state first\n",
        "        self.state = self.env.reset()\n",
        "        self.done = False\n",
        "\n",
        "        self.human_reward = 0\n",
        "        self.ai_reward = 0\n",
        "        \n",
        "        # Create UI elements\n",
        "        self.create_ui()\n",
        "\n",
        "        # Complete game state initialization\n",
        "        self.update_display()\n",
        "\n",
        "        # If AI goes first, make its move\n",
        "        if self.env.current_player == self.ai_player:\n",
        "            time.sleep(0.5)\n",
        "            self.make_ai_move()\n",
        "\n",
        "    def initialize_game_state(self):\n",
        "        \"\"\"Initialize the game state based on who starts first\"\"\"\n",
        "        # Reset game\n",
        "        self.state = self.env.reset()\n",
        "        self.done = False\n",
        "\n",
        "        # Update display\n",
        "        self.update_display()\n",
        "\n",
        "        # If AI goes first, make its move\n",
        "        if self.env.current_player == self.ai_player:\n",
        "            time.sleep(0.5)\n",
        "            self.make_ai_move()\n",
        "\n",
        "    def create_ui(self):\n",
        "        # Title\n",
        "        self.title = widgets.HTML(value=\"<h1 style='text-align: center;'>Connect 4</h1>\")\n",
        "\n",
        "        # Status message\n",
        "        self.status = widgets.HTML(value=\"<h3 style='text-align: center;'>Game ready! Make your move</h3>\")\n",
        "\n",
        "        # Create buttons for each column\n",
        "        self.buttons = []\n",
        "        for col in range(7):\n",
        "            btn = widgets.Button(description=str(col),\n",
        "                                layout=widgets.Layout(width='60px', height='40px'))\n",
        "            btn.on_click(lambda b, col=col: self.make_move(col))\n",
        "            self.buttons.append(btn)\n",
        "\n",
        "        # Button container (top row)\n",
        "        self.button_container = widgets.HBox(self.buttons,\n",
        "                                           layout=widgets.Layout(justify_content='center'))\n",
        "\n",
        "        # Game board display\n",
        "        self.board_display = widgets.HTML(value=self.render_board_html())\n",
        "\n",
        "        # Add Read Board button\n",
        "        self.read_board_button = widgets.Button(\n",
        "            description=\"Read Board\",\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        )\n",
        "        self.read_board_button.on_click(self.read_board_aloud)\n",
        "        \n",
        "        # Who starts selector\n",
        "        self.player_options = [('You start (X)', 1), ('AI starts (O)', -1)]\n",
        "        self.player_starter = widgets.RadioButtons(\n",
        "            options=self.player_options,\n",
        "            value=-1,  # Default to AI starting\n",
        "            description='New Game:',\n",
        "            layout=widgets.Layout(width='300px')\n",
        "        )\n",
        "\n",
        "        # New Game button\n",
        "        self.new_game_button = widgets.Button(\n",
        "            description=\"Start New Game\",\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        )\n",
        "        self.new_game_button.on_click(self.start_new_game)\n",
        "\n",
        "        # Game controls\n",
        "        self.game_controls = widgets.HBox([\n",
        "            self.player_starter,\n",
        "            self.new_game_button,\n",
        "            self.read_board_button  # Add the Read Board button to the controls\n",
        "        ], layout=widgets.Layout(justify_content='center', margin='20px 0'))\n",
        "\n",
        "        # Add file upload widget for voice commands\n",
        "        self.file_upload = widgets.FileUpload(\n",
        "            accept='',  # Accept all file types\n",
        "            multiple=False,  # Only allow single file upload\n",
        "            description='Voice Command:',\n",
        "            layout=widgets.Layout(width='250px')\n",
        "        )\n",
        "        self.file_upload.observe(self.handle_file_upload, names='value')\n",
        "\n",
        "        # Add submit button for processing the uploaded file\n",
        "        self.submit_button = widgets.Button(\n",
        "            description=\"Process Command\",\n",
        "            button_style='success',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        )\n",
        "        self.submit_button.on_click(self.process_audio_command)\n",
        "\n",
        "        # Audio controls\n",
        "        self.audio_controls = widgets.HBox([\n",
        "            self.file_upload,\n",
        "            self.submit_button\n",
        "        ], layout=widgets.Layout(justify_content='center', margin='10px 0'))\n",
        "\n",
        "        # Add upload status indicator\n",
        "        self.upload_status = widgets.HTML(value=\"<p>No file uploaded</p>\")\n",
        "\n",
        "        # Add status for speech synthesis\n",
        "        self.speech_status = widgets.HTML(value=\"\")\n",
        "\n",
        "        # Combine all widgets\n",
        "        self.app = widgets.VBox([\n",
        "            self.title,\n",
        "            self.status,\n",
        "            self.button_container,\n",
        "            self.board_display,\n",
        "            self.game_controls,\n",
        "            self.audio_controls,\n",
        "            self.upload_status,\n",
        "            self.speech_status\n",
        "        ], layout=widgets.Layout(width='100%', align_items='center'))\n",
        "\n",
        "        # Display the UI\n",
        "        display(self.app)\n",
        "        \n",
        "        # Add JavaScript for text-to-speech functionality\n",
        "        display(HTML(\"\"\"\n",
        "        <script>\n",
        "        function speakText(text) {\n",
        "            if ('speechSynthesis' in window) {\n",
        "                const utterance = new SpeechSynthesisUtterance(text);\n",
        "                utterance.rate = 1.0;  // Speech rate\n",
        "                utterance.pitch = 1.0; // Speech pitch\n",
        "                window.speechSynthesis.cancel(); // Cancel any ongoing speech\n",
        "                window.speechSynthesis.speak(utterance);\n",
        "                return \"Speaking...\";\n",
        "            } else {\n",
        "                return \"Text-to-speech not supported in this browser.\";\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        // Make the function available to Python\n",
        "        window.speakText = speakText;\n",
        "        </script>\n",
        "        \"\"\"))\n",
        "\n",
        "    def read_board_aloud(self, _=None):\n",
        "        \"\"\"Convert board state to spoken text and read it aloud\"\"\"\n",
        "        board_text = self.generate_board_description()\n",
        "        \n",
        "        # Use JavaScript to speak the text\n",
        "        js_code = f\"\"\"\n",
        "        var result = \"\";\n",
        "        if (typeof window.speakText === 'function') {{\n",
        "            result = window.speakText(\"{board_text}\");\n",
        "        }} else {{\n",
        "            result = \"Text-to-speech function not available.\";\n",
        "        }}\n",
        "        result;\n",
        "        \"\"\"\n",
        "        \n",
        "        # Execute the JavaScript to speak the text\n",
        "        try:\n",
        "            from IPython.display import Javascript\n",
        "            display(Javascript(js_code))\n",
        "            self.speech_status.value = \"<p>Reading board state aloud...</p>\"\n",
        "            \n",
        "            # Clear the status after 3 seconds\n",
        "            def clear_status():\n",
        "                time.sleep(3)\n",
        "                self.speech_status.value = \"\"\n",
        "            \n",
        "            import threading\n",
        "            threading.Thread(target=clear_status).start()\n",
        "            \n",
        "        except Exception as e:\n",
        "            self.speech_status.value = f\"<p style='color:red;'>Error with text-to-speech: {str(e)}</p>\"\n",
        "\n",
        "    def generate_board_description(self):\n",
        "        \"\"\"Generate a textual description of the board state\"\"\"\n",
        "        # Get the board from state\n",
        "        board = self.state[\"board\"]\n",
        "        rows, cols = board.shape\n",
        "        \n",
        "        # Start with the game status\n",
        "        if hasattr(self, 'done') and self.done:\n",
        "            if self._check_winner(1):\n",
        "                winner = 1\n",
        "            elif self._check_winner(-1):\n",
        "                winner = -1\n",
        "            else:\n",
        "                winner = 0\n",
        "                \n",
        "            if winner == 1:\n",
        "                status = \"Player X has won. \" if self.ai_player == -1 else \"AI has won. \"\n",
        "            elif winner == -1:\n",
        "                status = \"AI has won. \" if self.ai_player == -1 else \"Player X has won. \"\n",
        "            else:\n",
        "                status = \"The game is a draw. \"\n",
        "        else:\n",
        "            human_player = -self.ai_player\n",
        "            if self.env.current_player == human_player:\n",
        "                player_name = \"Your\"\n",
        "                player_symbol = \"X\" if human_player == 1 else \"O\"\n",
        "            else:\n",
        "                player_name = \"AI's\"\n",
        "                player_symbol = \"X\" if self.ai_player == 1 else \"O\"\n",
        "                \n",
        "            status = f\"It is {player_name} turn with {player_symbol}. \"\n",
        "        \n",
        "        # Describe the board\n",
        "        board_desc = \"Board state: \"\n",
        "        \n",
        "        # Count pieces by column\n",
        "        for col in range(cols):\n",
        "            pieces = []\n",
        "            for row in range(rows-1, -1, -1):  # Start from bottom row\n",
        "                if board[row, col] == 1:\n",
        "                    pieces.append(\"X\")\n",
        "                elif board[row, col] == -1:\n",
        "                    pieces.append(\"O\")\n",
        "            \n",
        "            if pieces:\n",
        "                board_desc += f\"Column {col} has {len(pieces)} pieces: {', '.join(pieces)} from bottom to top. \"\n",
        "            else:\n",
        "                board_desc += f\"Column {col} is empty. \"\n",
        "        \n",
        "        # Escape quotes and special characters\n",
        "        full_description = status + board_desc\n",
        "        full_description = full_description.replace('\"', '\\\\\"').replace(\"'\", \"\\\\'\")\n",
        "        \n",
        "        return full_description\n",
        "\n",
        "    def handle_file_upload(self, change):\n",
        "        \"\"\"Handle file upload event\"\"\"\n",
        "        if change['new']:\n",
        "            try:\n",
        "                # Check if change['new'] is a tuple or a dictionary\n",
        "                if isinstance(change['new'], tuple):\n",
        "                    # If it's a tuple, extract the first element\n",
        "                    uploaded_file = change['new'][0]\n",
        "                else:\n",
        "                    # If it's a dictionary, use the original code\n",
        "                    uploaded_file = next(iter(change['new'].values()))\n",
        "                \n",
        "                # Check if 'metadata' exists in the structure\n",
        "                if 'metadata' in uploaded_file and 'name' in uploaded_file['metadata']:\n",
        "                    filename = uploaded_file['metadata']['name']\n",
        "                    # Just acknowledge the upload\n",
        "                    self.upload_status.value = f\"<p>File uploaded: {filename}</p>\"\n",
        "                else:\n",
        "                    # Handle case where metadata or name is missing\n",
        "                    self.upload_status.value = f\"<p>File uploaded successfully</p>\"\n",
        "                \n",
        "                self.upload_status.value += f\"<p>Click 'Process Command' to execute the command.</p>\"\n",
        "            except Exception as e:\n",
        "                # Fallback for any unexpected structure\n",
        "                self.upload_status.value = f\"<p>File uploaded, but couldn't read file details: {str(e)}</p>\"\n",
        "                self.upload_status.value += f\"<p>Click 'Process Command' to execute the command.</p>\"\n",
        "\n",
        "    def process_audio_command(self, _=None):\n",
        "        \"\"\"Process an uploaded audio file and dispatch the spoken command.\"\"\"\n",
        "        try:\n",
        "            # ── 1. Validate upload ────────────────────────────────────────────────\n",
        "            if not self.file_upload.value:\n",
        "                self.upload_status.value = (\n",
        "                    \"<p style='color:orange;'>Please upload an audio file first.</p>\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            try:\n",
        "                # Check if file_upload.value is a tuple or a dictionary\n",
        "                if isinstance(self.file_upload.value, tuple):\n",
        "                    # If it's a tuple, extract the first element\n",
        "                    uploaded = self.file_upload.value[0]\n",
        "                else:\n",
        "                    # If it's a dictionary, use the original code\n",
        "                    uploaded = next(iter(self.file_upload.value.values()))\n",
        "                \n",
        "                # Check if 'content' exists\n",
        "                if 'content' not in uploaded:\n",
        "                    self.upload_status.value = (\n",
        "                        \"<p style='color:red;'>Invalid file format: missing content</p>\"\n",
        "                    )\n",
        "                    return\n",
        "                    \n",
        "                raw_bytes = uploaded[\"content\"]\n",
        "                \n",
        "                # Try to get filename but provide default if not available\n",
        "                fname = \"uploaded_audio\"\n",
        "                if 'metadata' in uploaded and 'name' in uploaded['metadata']:\n",
        "                    fname = uploaded['metadata']['name']\n",
        "            except Exception as e:\n",
        "                self.upload_status.value = (\n",
        "                    f\"<p style='color:red;'>Error reading file: {str(e)}</p>\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            self.upload_status.value = \"<p style='color:blue;'>Processing audio file...</p>\"\n",
        "\n",
        "            # You need to import these libraries in your notebook\n",
        "            # If these imports are failing, install the libraries first:\n",
        "            # !pip install SpeechRecognition pydub\n",
        "            try:\n",
        "                import speech_recognition as sr\n",
        "                from pydub import AudioSegment\n",
        "            except ImportError as e:\n",
        "                self.upload_status.value = (\n",
        "                    \"<p style='color:red;'>Missing required Python libraries. Please run the following in a cell:</p>\"\n",
        "                    \"<pre>!pip install SpeechRecognition pydub</pre>\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            # ── 2. Convert to mono-WAV in-memory (handles mp3, wav, m4a, etc.) ────\n",
        "            try:\n",
        "                # This will fail if ffmpeg/ffprobe is not installed\n",
        "                audio = AudioSegment.from_file(io.BytesIO(raw_bytes))\n",
        "                audio = audio.set_frame_rate(16_000).set_channels(1)\n",
        "                with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as wav_tmp:\n",
        "                    audio.export(wav_tmp.name, format=\"wav\")\n",
        "                    wav_path = wav_tmp.name\n",
        "            except FileNotFoundError as err:\n",
        "                if 'ffprobe' in str(err) or 'ffmpeg' in str(err):\n",
        "                    self.upload_status.value = (\n",
        "                        \"<p style='color:red;'>Missing FFmpeg tools. This feature requires FFmpeg to be installed.</p>\"\n",
        "                        \"<p>Please install FFmpeg by running the following command in a cell:</p>\"\n",
        "                        \"<pre>!apt-get update && apt-get install -y ffmpeg</pre>\"\n",
        "                        \"<p>If using Google Colab, run:</p>\"\n",
        "                        \"<pre>!apt-get update && apt-get install -y ffmpeg</pre>\"\n",
        "                        \"<p>If using a local environment, install FFmpeg using your package manager, e.g.:</p>\"\n",
        "                        \"<p>- Ubuntu/Debian: <code>sudo apt install ffmpeg</code></p>\"\n",
        "                        \"<p>- macOS: <code>brew install ffmpeg</code></p>\"\n",
        "                        \"<p>- Windows: <a href='https://ffmpeg.org/download.html'>Download from ffmpeg.org</a></p>\"\n",
        "                    )\n",
        "                else:\n",
        "                    self.upload_status.value = (\n",
        "                        f\"<p style='color:red;'>Error: {str(err)}</p>\"\n",
        "                    )\n",
        "                return\n",
        "            except Exception as exc:\n",
        "                self.upload_status.value = (\n",
        "                    \"<p style='color:red;'>Cannot process audio \\\"\" + fname + \"\\\": \" + str(exc) + \"</p>\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            # ── 3. Speech-to-text (Google Web API) ────────────────────────────────\n",
        "            try:\n",
        "                recog = sr.Recognizer()\n",
        "                with sr.AudioFile(wav_path) as source:\n",
        "                    # remove ambient-noise adjustment for prerecorded files\n",
        "                    audio_data = recog.record(source)      # grab the whole file\n",
        "                text = recog.recognize_google(audio_data, language='en-US').lower()\n",
        "                self.upload_status.value = f\"<p>Heard: \\\"{text}\\\"</p>\"\n",
        "            except sr.UnknownValueError:\n",
        "                self.upload_status.value = (\n",
        "                    \"<p style='color:red;'>Sorry, I couldn't understand that.</p>\"\n",
        "                )\n",
        "                return\n",
        "            except sr.RequestError as exc:\n",
        "                self.upload_status.value = (\n",
        "                    \"<p style='color:red;'>Speech-service error: \" + str(exc) + \"</p>\"\n",
        "                )\n",
        "                return\n",
        "            finally:\n",
        "                # Clean temp file\n",
        "                with suppress(FileNotFoundError):\n",
        "                    os.remove(wav_path)\n",
        "\n",
        "            # ── 4. Command routing ────────────────────────────────────────────────\n",
        "            digit_words = {\n",
        "                \"zero\": 0,\n",
        "                \"one\": 1,\n",
        "                \"two\": 2,\n",
        "                \"three\": 3,\n",
        "                \"four\": 4,\n",
        "                \"five\": 5,\n",
        "                \"six\": 6,\n",
        "            }\n",
        "\n",
        "            # Add handling for \"read board\" command\n",
        "            if re.search(r\"\\bread\\b.*\\bboard\\b\", text):\n",
        "                self.upload_status.value += \"<p>Reading board state...</p>\"\n",
        "                self.read_board_aloud(None)\n",
        "                return\n",
        "\n",
        "            # new-game\n",
        "            if re.search(r\"\\bnew\\b.*\\bgame\\b\", text):\n",
        "                self.upload_status.value += \"<p>Starting a new game!</p>\"\n",
        "                self.start_new_game(None)\n",
        "                return\n",
        "\n",
        "            # column n / just n\n",
        "            # 1️⃣ match \"column three\", \"col 3\", \"place in five\" …\n",
        "            col_match = re.search(r\"\\b(col(?:umn)?|place(?:\\sin)?)\\s*(\\w+)\", text)\n",
        "            word_or_digit = None\n",
        "            if col_match:\n",
        "                word_or_digit = col_match.group(2)\n",
        "            else:\n",
        "                # 2️⃣ plain \"three\" / \"3\"\n",
        "                word_or_digit = text.strip()\n",
        "\n",
        "            # map to integer 0-6\n",
        "            if word_or_digit in digit_words:\n",
        "                col = digit_words[word_or_digit]\n",
        "            elif word_or_digit.isdigit() and 0 <= int(word_or_digit) <= 6:\n",
        "                col = int(word_or_digit)\n",
        "            else:\n",
        "                self.upload_status.value += (\n",
        "                    \"<p style='color:orange;'>Command not recognized. \"\n",
        "                    \"Say e.g. \\\"column three\\\", \\\"new game\\\", or \\\"read board\\\".</p>\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            # ── 5. Execute move ───────────────────────────────────────────────────\n",
        "            self.upload_status.value += f\"<p>Placing piece in column {col}</p>\"\n",
        "            self.make_move(col)\n",
        "\n",
        "            # ── 6. Reset uploader for next use ────────────────────────────────────\n",
        "            try:\n",
        "                if isinstance(self.file_upload.value, tuple):\n",
        "                    self.file_upload.value = ()  # Clear tuple\n",
        "                else:\n",
        "                    self.file_upload.value.clear()  # Clear dictionary\n",
        "            except Exception as e:\n",
        "                # Just ignore errors in clearing\n",
        "                pass\n",
        "\n",
        "        except ImportError as e:\n",
        "            self.upload_status.value = (\n",
        "                \"<p style='color:red;'>Missing required libraries: \" + str(e) + \". \"\n",
        "                \"Please install the required libraries using !pip install.</p>\"\n",
        "            )\n",
        "        except Exception as e:\n",
        "            self.upload_status.value = (\n",
        "                \"<p style='color:red;'>Error processing audio: \" + str(e) + \"</p>\"\n",
        "            )\n",
        "\n",
        "    def start_new_game(self, b):\n",
        "        \"\"\"Start a new game with the selected starting player\"\"\"\n",
        "        # Get who starts from the radio buttons\n",
        "        selected_value = self.player_starter.value\n",
        "\n",
        "        # Figure out who the AI player is based on selected value\n",
        "        self.ai_player = -selected_value\n",
        "        \n",
        "        # Assign the right model based on which player the AI is\n",
        "        self.model = self.model_p2 if self.ai_player == -1 else self.model_p1\n",
        "        \n",
        "        # Reset the game\n",
        "        self.state = self.env.reset()\n",
        "        self.done = False\n",
        "\n",
        "        self.human_reward = 0\n",
        "        self.ai_reward = 0\n",
        "\n",
        "        # Re-enable buttons\n",
        "        for btn in self.buttons:\n",
        "            btn.disabled = False\n",
        "\n",
        "        # Update the display\n",
        "        self.update_display()\n",
        "\n",
        "        # If AI goes first, make its move\n",
        "        if self.env.current_player == self.ai_player:\n",
        "            time.sleep(0.5)\n",
        "            self.make_ai_move()\n",
        "\n",
        "    def render_board_html(self):\n",
        "        \"\"\"Render the Connect 4 board as HTML for display\"\"\"\n",
        "        html = \"\"\"\n",
        "        <style>\n",
        "        .board {\n",
        "            background-color: #0052cc;\n",
        "            display: inline-block;\n",
        "            padding: 10px;\n",
        "            border-radius: 10px;\n",
        "        }\n",
        "        .cell {\n",
        "            width: 60px;\n",
        "            height: 60px;\n",
        "            background-color: #ffffff;\n",
        "            border-radius: 50%;\n",
        "            display: inline-block;\n",
        "            margin: 5px;\n",
        "        }\n",
        "        .player1 {\n",
        "            background-color: #ff0000;\n",
        "        }\n",
        "        .player-1 {\n",
        "            background-color: #ffff00;\n",
        "        }\n",
        "        </style>\n",
        "        <div class=\"board\">\n",
        "        \"\"\"\n",
        "\n",
        "        # Get board from state\n",
        "        board = self.state[\"board\"]\n",
        "        rows, cols = board.shape\n",
        "        \n",
        "        for row in range(rows):\n",
        "            html += \"<div>\"\n",
        "            for col in range(cols):\n",
        "                cell_value = board[row, col]\n",
        "                cell_class = f\"cell player{cell_value}\" if cell_value != 0 else \"cell\"\n",
        "                html += f'<div class=\"{cell_class}\"></div>'\n",
        "            html += \"</div>\"\n",
        "\n",
        "        html += \"</div>\"\n",
        "        return html\n",
        "\n",
        "    def update_display(self):\n",
        "        \"\"\"Update the board display and status message\"\"\"\n",
        "        self.board_display.value = self.render_board_html()\n",
        "\n",
        "        # Check game status\n",
        "        if hasattr(self, 'done') and self.done:\n",
        "            # Game is over\n",
        "            if self._check_winner(1):\n",
        "                winner = 1\n",
        "            elif self._check_winner(-1):\n",
        "                winner = -1\n",
        "            else:\n",
        "                winner = 0  # Draw\n",
        "\n",
        "            if winner == 1:\n",
        "                message = \"You win! 🎉\" if self.ai_player == -1 else \"AI wins! 🤖\"\n",
        "                color = \"green\" if self.ai_player == -1 else \"red\"\n",
        "            elif winner == -1:\n",
        "                message = \"AI wins! 🤖\" if self.ai_player == -1 else \"You win! 🎉\"\n",
        "                color = \"red\" if self.ai_player == -1 else \"green\"\n",
        "            else:\n",
        "                message = \"Draw game! 🤝\"\n",
        "                color = \"blue\"\n",
        "\n",
        "            self.status.value = f\"<h3 style='text-align: center; color: {color};'>{message}</h3><p>Human reward: {self.human_reward}</p><p>AI reward: {self.ai_reward}</p>\"\n",
        "\n",
        "            # Disable column buttons\n",
        "            for btn in self.buttons:\n",
        "                btn.disabled = True\n",
        "        else:\n",
        "            # Game is ongoing\n",
        "            current_player = self.env.current_player\n",
        "            human_player = -self.ai_player\n",
        "\n",
        "            if current_player == human_player:\n",
        "                player_name = \"Your\"\n",
        "                player_symbol = \"(X)\" if human_player == 1 else \"(O)\"\n",
        "            else:\n",
        "                player_name = \"AI's\"\n",
        "                player_symbol = \"(X)\" if self.ai_player == 1 else \"(O)\"\n",
        "\n",
        "            self.status.value = f\"<h3 style='text-align: center;'>{player_name} turn {player_symbol}</h3>\"\n",
        "\n",
        "    def valid_actions(self):\n",
        "        \"\"\"Helper method to get valid actions from BoardEnv\"\"\"\n",
        "        # Add this method to simulate the Connect4Env's valid_actions method\n",
        "        return [c for c in range(7) if self.env._is_valid_action(c)]\n",
        "\n",
        "    def make_move(self, column):\n",
        "        \"\"\"Handle player's move on column click\"\"\"\n",
        "        if hasattr(self, 'done') and self.done:\n",
        "            # Game is already over\n",
        "            return\n",
        "\n",
        "        # Determine if it's human's turn\n",
        "        human_player = -self.ai_player\n",
        "        if self.env.current_player != human_player:\n",
        "            self.status.value = \"<h3 style='text-align: center; color: orange;'>Not your turn!</h3>\"\n",
        "            return\n",
        "\n",
        "        # Check if move is valid\n",
        "        if not self.env._is_valid_action(column):  # Changed from valid_actions to _is_valid_action\n",
        "            self.status.value = \"<h3 style='text-align: center; color: orange;'>Invalid move! Column is full</h3>\"\n",
        "            return\n",
        "\n",
        "        # Make the move\n",
        "        next_state, reward, done, _ = self.env.step(column)\n",
        "        self.state = next_state\n",
        "        self.done = done\n",
        "\n",
        "        self.human_reward += reward\n",
        "\n",
        "        # Update the display\n",
        "        self.update_display()\n",
        "\n",
        "        # If game not over and AI's turn, make AI move\n",
        "        if not done and self.env.current_player == self.ai_player:\n",
        "            # Add a small delay for better UX\n",
        "            time.sleep(0.5)\n",
        "            self.make_ai_move()\n",
        "\n",
        "    def make_ai_move(self):\n",
        "        \"\"\"Make an AI move using the model\"\"\"\n",
        "        if hasattr(self, 'done') and self.done:\n",
        "            return\n",
        "\n",
        "        # Use the model to select an action\n",
        "        # Prepare tensor\n",
        "        state_tensor = torch.tensor(self.state[\"board\"], dtype=torch.float32, device=device).unsqueeze(0).unsqueeze(0)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            qvals = self.model(state_tensor)\n",
        "            # Mask out illegal moves\n",
        "            illegal_mask = get_illegal_moves_mask(self.state[\"board\"])\n",
        "            qvals[0][illegal_mask] = -1e9\n",
        "            action = qvals.argmax(dim=1).item()\n",
        "\n",
        "        # Make the move\n",
        "        next_state, reward, done, _ = self.env.step(action)\n",
        "        self.state = next_state\n",
        "        self.done = done\n",
        "\n",
        "        self.ai_reward += reward\n",
        "\n",
        "        # Update the display\n",
        "        self.update_display() \n",
        "\n",
        "    def _check_winner(self, player):\n",
        "        \"\"\"Check if given player has won by having 4 in a row anywhere on the board\"\"\"\n",
        "        # Can only win if player is 1 (X) or -1 (O)\n",
        "        if player == 0:\n",
        "            return False\n",
        "            \n",
        "        board = self.state[\"board\"]  # Use self.state[\"board\"] instead of self.env.state[\"board\"]\n",
        "        rows, cols = board.shape\n",
        "    \n",
        "        # Horizontal check\n",
        "        for r in range(rows):\n",
        "            for c in range(cols - 3):\n",
        "                if (board[r, c] == player and \n",
        "                    board[r, c+1] == player and \n",
        "                    board[r, c+2] == player and \n",
        "                    board[r, c+3] == player):\n",
        "                    return True\n",
        "        \n",
        "        # Vertical check\n",
        "        for r in range(rows - 3):\n",
        "            for c in range(cols):\n",
        "                if (board[r, c] == player and \n",
        "                    board[r+1, c] == player and \n",
        "                    board[r+2, c] == player and \n",
        "                    board[r+3, c] == player):\n",
        "                    return True\n",
        "        \n",
        "        # Diagonal down-right\n",
        "        for r in range(rows - 3):\n",
        "            for c in range(cols - 3):\n",
        "                if (board[r, c] == player and \n",
        "                    board[r+1, c+1] == player and \n",
        "                    board[r+2, c+2] == player and \n",
        "                    board[r+3, c+3] == player):\n",
        "                    return True\n",
        "        \n",
        "        # Diagonal up-right\n",
        "        for r in range(3, rows):\n",
        "            for c in range(cols - 3):\n",
        "                if (board[r, c] == player and \n",
        "                    board[r-1, c+1] == player and \n",
        "                    board[r-2, c+2] == player and \n",
        "                    board[r-3, c+3] == player):\n",
        "                    return True\n",
        "        \n",
        "        return False\n",
        "\n",
        "def start_connect4_ui(model_p1, model_p2, ai_player=-1):\n",
        "    \"\"\"\n",
        "    Start the Connect4 UI with the trained models\n",
        "\n",
        "    Args:\n",
        "        model_p1: The trained DQN model for player 1\n",
        "        model_p2: The trained DQN model for player 2\n",
        "        ai_player: The player ID for the AI (-1 or 1)\n",
        "    \"\"\"\n",
        "    ui = Connect4UI(model_p1, model_p2, ai_player=ai_player)\n",
        "    return ui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Metrics\n",
        "\n",
        "As training proceeds, we collect metrics like average reward per episode and epsilon value. This cell uses TensorBoard to plot those curves, so you can visually confirm that:\n",
        "\n",
        "- Rewards increase over time (the agent is learning).\n",
        "\n",
        "- Epsilon decays smoothly (less random play as training continues)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "source code string cannot contain null bytes",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[31mValueError\u001b[39m: source code string cannot contain null bytes"
          ]
        }
      ],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Play Model\n",
        "\n",
        "Finally, we launch the UI and let our trained agent play"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f853d76d150b4e52b7ed96a8627e29a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value=\"<h1 style='text-align: center;'>Connect 4</h1>\"), HTML(value=\"<h3 style='text-align…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <script>\n",
              "        function speakText(text) {\n",
              "            if ('speechSynthesis' in window) {\n",
              "                const utterance = new SpeechSynthesisUtterance(text);\n",
              "                utterance.rate = 1.0;  // Speech rate\n",
              "                utterance.pitch = 1.0; // Speech pitch\n",
              "                window.speechSynthesis.cancel(); // Cancel any ongoing speech\n",
              "                window.speechSynthesis.speak(utterance);\n",
              "                return \"Speaking...\";\n",
              "            } else {\n",
              "                return \"Text-to-speech not supported in this browser.\";\n",
              "            }\n",
              "        }\n",
              "\n",
              "        // Make the function available to Python\n",
              "        window.speakText = speakText;\n",
              "        </script>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def start_connect4_ui(model_p1, model_p2, ai_player=-1):\n",
        "    \"\"\"\n",
        "    Start the Connect4 UI with the trained models\n",
        "\n",
        "    Args:\n",
        "        model_p1: The trained DQN model for player 1\n",
        "        model_p2: The trained DQN model for player 2\n",
        "        ai_player: The player ID for the AI (-1 or 1)\n",
        "    \"\"\"\n",
        "    ui = Connect4UI(model_p1, model_p2, ai_player=ai_player)\n",
        "    return ui\n",
        "\n",
        "# Load your trained models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_p1 = ConvQNetwork(input_shape=(1,6,7), num_actions=7).to(device)\n",
        "model_p2 = ConvQNetwork(input_shape=(1,6,7), num_actions=7).to(device)\n",
        "\n",
        "# Load saved model weights\n",
        "model_p1.load_state_dict(torch.load(\"checkpoints/c4_dqn/Player1_Final.pth\", map_location=device))\n",
        "model_p2.load_state_dict(torch.load(\"checkpoints/c4_dqn/Player2_Final.pth\", map_location=device))\n",
        "\n",
        "# Set models to evaluation mode\n",
        "model_p1.eval()\n",
        "model_p2.eval()\n",
        "\n",
        "ui = start_connect4_ui(model_p1, model_p2, ai_player=-1)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
