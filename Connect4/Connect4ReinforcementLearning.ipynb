{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzH7tgStJksW"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M5HyqW2FJioP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "Using device: cuda\n",
            "CUDA device name: NVIDIA GeForce RTX 3070 Ti Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.is_available())\n",
        "print(\"Using device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_device(tensor):\n",
        "    return tensor.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1c6KRsCJpvG"
      },
      "source": [
        "Class for connect4 environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QfxUylEHJw5Q"
      },
      "outputs": [],
      "source": [
        "class Connect4Env:\n",
        "    def __init__(self):\n",
        "        self.rows = 6\n",
        "        self.cols = 7\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.board = np.zeros((self.rows, self.cols), dtype=int)\n",
        "        self.current_player = 1\n",
        "        self.last_move = None\n",
        "        return self._get_obs()\n",
        "\n",
        "    def _get_obs(self):\n",
        "        p1_board = (self.board == 1).astype(np.float32)\n",
        "        p2_board = (self.board == -1).astype(np.float32)\n",
        "        if self.current_player == 1:\n",
        "            return np.stack([p1_board, p2_board], axis=0)\n",
        "        else:\n",
        "            return np.stack([p2_board, p1_board], axis=0)\n",
        "\n",
        "    def valid_actions(self):\n",
        "        return [c for c in range(self.cols) if self.board[0, c] == 0]\n",
        "\n",
        "    def step(self, action):\n",
        "        if action not in self.valid_actions():\n",
        "            return self._get_obs(), -10, True, {}\n",
        "\n",
        "        for r in range(self.rows - 1, -1, -1):\n",
        "            if self.board[r, action] == 0:\n",
        "                self.board[r, action] = self.current_player\n",
        "                self.last_move = (r, action)\n",
        "                break\n",
        "\n",
        "        if self._check_winner(self.current_player, self.last_move):\n",
        "            return self._get_obs(), 1, True, {}\n",
        "\n",
        "        if len(self.valid_actions()) == 0:\n",
        "            return self._get_obs(), 0, True, {}\n",
        "\n",
        "        self.current_player *= -1\n",
        "        return self._get_obs(), -0.01, False, {}\n",
        "\n",
        "    def _check_winner(self, player, last_move):\n",
        "        if last_move is None:\n",
        "            return False\n",
        "        r, c = last_move\n",
        "        directions = [(1, 0), (0, 1), (1, 1), (1, -1)]\n",
        "        for dr, dc in directions:\n",
        "            count = 1\n",
        "            for d in [-1, 1]:\n",
        "                nr, nc = r + d * dr, c + d * dc\n",
        "                while 0 <= nr < self.rows and 0 <= nc < self.cols and self.board[nr, nc] == player:\n",
        "                    count += 1\n",
        "                    if count >= 4:\n",
        "                        return True\n",
        "                    nr += d * dr\n",
        "                    nc += d * dc\n",
        "        return False\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJdsV1swJ3lg"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YaLFrL97J3QU"
      },
      "outputs": [],
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 6 * 7, 128)\n",
        "        self.out = nn.Linear(128, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.out(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xljipnuZKGS1"
      },
      "source": [
        "Replay Buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Lf85V8OwKJta"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity=10000):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, transition):\n",
        "        self.buffer.append(transition)\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.buffer, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csLuvB18KKjR"
      },
      "source": [
        "Selecting Action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AQMGWMxsKP1v"
      },
      "outputs": [],
      "source": [
        "# --- Training Functions ---\n",
        "def select_action(model, state, epsilon, valid_actions):\n",
        "    if random.random() < epsilon:\n",
        "        return random.choice(valid_actions)\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            q_values = model(torch.tensor(state, dtype=torch.float32).unsqueeze(0).to(device))\n",
        "            q_values = q_values.squeeze()\n",
        "            q_values[[i for i in range(7) if i not in valid_actions]] = -float('inf')\n",
        "            return torch.argmax(q_values).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_i6kGwpKSZ_"
      },
      "source": [
        "Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "De4_ZhldKU00"
      },
      "outputs": [],
      "source": [
        "def train_self_play(episodes=50000, epsilon=1.0, epsilon_min=0.1, epsilon_decay=0.995,\n",
        "                     gamma=0.99, batch_size=64, update_target_every=10):\n",
        "    env = Connect4Env()\n",
        "    model1 = DQN().to(device)  # Player 1\n",
        "    model2 = DQN().to(device)  # Player -1\n",
        "    target_model1 = DQN().to(device)\n",
        "    target_model2 = DQN().to(device)\n",
        "    target_model1.load_state_dict(model1.state_dict())\n",
        "    target_model2.load_state_dict(model2.state_dict())\n",
        "    optimizer1 = optim.Adam(model1.parameters(), lr=1e-3)\n",
        "    optimizer2 = optim.Adam(model2.parameters(), lr=1e-3)\n",
        "    buffer1 = ReplayBuffer()\n",
        "    buffer2 = ReplayBuffer()\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        reward_p1 = 0\n",
        "        reward_p2 = 0\n",
        "\n",
        "        while not done:\n",
        "            current_player = env.current_player\n",
        "            model = model1 if current_player == 1 else model2\n",
        "            buffer = buffer1 if current_player == 1 else buffer2\n",
        "            optimizer = optimizer1 if current_player == 1 else optimizer2\n",
        "            target_model = target_model1 if current_player == 1 else target_model2\n",
        "\n",
        "            valid_actions = env.valid_actions()\n",
        "            action = select_action(model, state, epsilon, valid_actions)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            if done and reward == 1:\n",
        "                # Penalize the opponent for losing\n",
        "                opponent_buffer = buffer2 if current_player == 1 else buffer1\n",
        "                if len(opponent_buffer) > 0:\n",
        "                    last_state, last_action, _, last_next_state, last_done = opponent_buffer.buffer[-1]\n",
        "                    opponent_buffer.buffer[-1] = (last_state, last_action, -1.0, last_next_state, last_done)\n",
        "            buffer.push((np.array(state, copy=True), action, reward, np.array(next_state, copy=True), done))\n",
        "            state = next_state\n",
        "            if current_player == 1:\n",
        "                reward_p1 += reward\n",
        "            else:\n",
        "                reward_p2 += reward\n",
        "\n",
        "            if len(buffer) >= batch_size:\n",
        "                transitions = buffer.sample(batch_size)\n",
        "                states, actions, rewards, next_states, dones = zip(*transitions)\n",
        "\n",
        "                states = torch.tensor(np.stack(states), dtype=torch.float32).to(device)\n",
        "                actions = torch.tensor(actions).unsqueeze(1).to(device)\n",
        "                rewards = torch.tensor(rewards).unsqueeze(1).to(device)\n",
        "                next_states = torch.tensor(np.stack(next_states), dtype=torch.float32).to(device)\n",
        "                dones = torch.tensor(dones, dtype=torch.float32).unsqueeze(1).to(device)\n",
        "\n",
        "                q_values = model(states).gather(1, actions)\n",
        "                with torch.no_grad():\n",
        "                    max_next_q = target_model(next_states).max(1)[0].unsqueeze(1)\n",
        "                    target_q = rewards + gamma * max_next_q * (1 - dones)\n",
        "\n",
        "                loss = F.mse_loss(q_values, target_q)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        if epsilon > epsilon_min:\n",
        "            epsilon *= epsilon_decay\n",
        "\n",
        "        if episode % update_target_every == 0:\n",
        "            target_model1.load_state_dict(model1.state_dict())\n",
        "            target_model2.load_state_dict(model2.state_dict())\n",
        "\n",
        "        if episode % 10000 == 0 and episode > 0:\n",
        "            torch.save(model1.state_dict(), f\"connect4_model1_ep{episode}.pth\")\n",
        "            torch.save(model2.state_dict(), f\"connect4_model2_ep{episode}.pth\")\n",
        "\n",
        "        if episode % 100 == 0: print(f\"Episode {episode}, P1 reward: {reward_p1:.2f}, P2 reward: {reward_p2:.2f}, Epsilon: {epsilon:.3f}\")\n",
        "\n",
        "    torch.save(model1.state_dict(), \"connect4_model1_final.pth\")\n",
        "    torch.save(model2.state_dict(), \"connect4_model2_final.pth\")\n",
        "    return model1, model2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXKXWYDSKYn1"
      },
      "source": [
        "Train It"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "8aeN-tkFKaRm",
        "outputId": "81958218-079e-4436-a746-783ec15a9370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 1.000\n",
            "Episode 100, P1 reward: 0.91, P2 reward: -0.09, Epsilon: 0.951\n",
            "Episode 200, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.904\n",
            "Episode 300, P1 reward: -0.13, P2 reward: 0.88, Epsilon: 0.860\n",
            "Episode 400, P1 reward: 0.89, P2 reward: -0.11, Epsilon: 0.818\n",
            "Episode 500, P1 reward: 0.96, P2 reward: -0.04, Epsilon: 0.778\n",
            "Episode 600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.740\n",
            "Episode 700, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.704\n",
            "Episode 800, P1 reward: 0.97, P2 reward: -0.03, Epsilon: 0.670\n",
            "Episode 900, P1 reward: 0.91, P2 reward: -0.09, Epsilon: 0.637\n",
            "Episode 1000, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.606\n",
            "Episode 1100, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.577\n",
            "Episode 1200, P1 reward: 0.97, P2 reward: -0.03, Epsilon: 0.548\n",
            "Episode 1300, P1 reward: 0.91, P2 reward: -0.09, Epsilon: 0.522\n",
            "Episode 1400, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.496\n",
            "Episode 1500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.472\n",
            "Episode 1600, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.449\n",
            "Episode 1700, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.427\n",
            "Episode 1800, P1 reward: -0.12, P2 reward: 0.89, Epsilon: 0.406\n",
            "Episode 1900, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.386\n",
            "Episode 2000, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.368\n",
            "Episode 2100, P1 reward: 0.90, P2 reward: -0.10, Epsilon: 0.350\n",
            "Episode 2200, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.333\n",
            "Episode 2300, P1 reward: 0.86, P2 reward: -0.14, Epsilon: 0.316\n",
            "Episode 2400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.301\n",
            "Episode 2500, P1 reward: 0.90, P2 reward: -0.10, Epsilon: 0.286\n",
            "Episode 2600, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.272\n",
            "Episode 2700, P1 reward: -0.14, P2 reward: 0.87, Epsilon: 0.259\n",
            "Episode 2800, P1 reward: -0.14, P2 reward: 0.87, Epsilon: 0.246\n",
            "Episode 2900, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.234\n",
            "Episode 3000, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.223\n",
            "Episode 3100, P1 reward: 0.86, P2 reward: -0.14, Epsilon: 0.212\n",
            "Episode 3200, P1 reward: 0.90, P2 reward: -0.10, Epsilon: 0.202\n",
            "Episode 3300, P1 reward: -0.13, P2 reward: 0.88, Epsilon: 0.192\n",
            "Episode 3400, P1 reward: -0.11, P2 reward: 0.90, Epsilon: 0.183\n",
            "Episode 3500, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.174\n",
            "Episode 3600, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.165\n",
            "Episode 3700, P1 reward: 0.91, P2 reward: -0.09, Epsilon: 0.157\n",
            "Episode 3800, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.149\n",
            "Episode 3900, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.142\n",
            "Episode 4000, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.135\n",
            "Episode 4100, P1 reward: 0.90, P2 reward: -0.10, Epsilon: 0.129\n",
            "Episode 4200, P1 reward: -0.12, P2 reward: 0.89, Epsilon: 0.122\n",
            "Episode 4300, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.116\n",
            "Episode 4400, P1 reward: -0.14, P2 reward: 0.87, Epsilon: 0.111\n",
            "Episode 4500, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.105\n",
            "Episode 4600, P1 reward: -0.15, P2 reward: 0.86, Epsilon: 0.100\n",
            "Episode 4700, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 4800, P1 reward: -0.13, P2 reward: 0.88, Epsilon: 0.100\n",
            "Episode 4900, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 5000, P1 reward: 0.87, P2 reward: -0.13, Epsilon: 0.100\n",
            "Episode 5100, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 5200, P1 reward: 0.86, P2 reward: -0.14, Epsilon: 0.100\n",
            "Episode 5300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 5400, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.100\n",
            "Episode 5500, P1 reward: 0.89, P2 reward: -0.11, Epsilon: 0.100\n",
            "Episode 5600, P1 reward: 0.87, P2 reward: -0.13, Epsilon: 0.100\n",
            "Episode 5700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 5800, P1 reward: 0.90, P2 reward: -0.10, Epsilon: 0.100\n",
            "Episode 5900, P1 reward: 0.89, P2 reward: -0.11, Epsilon: 0.100\n",
            "Episode 6000, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.100\n",
            "Episode 6100, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 6200, P1 reward: 0.90, P2 reward: -0.10, Epsilon: 0.100\n",
            "Episode 6300, P1 reward: 0.87, P2 reward: -0.13, Epsilon: 0.100\n",
            "Episode 6400, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.100\n",
            "Episode 6500, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 6600, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.100\n",
            "Episode 6700, P1 reward: 0.89, P2 reward: -0.11, Epsilon: 0.100\n",
            "Episode 6800, P1 reward: 0.87, P2 reward: -0.13, Epsilon: 0.100\n",
            "Episode 6900, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 7000, P1 reward: -0.12, P2 reward: 0.89, Epsilon: 0.100\n",
            "Episode 7100, P1 reward: -0.12, P2 reward: 0.89, Epsilon: 0.100\n",
            "Episode 7200, P1 reward: -0.15, P2 reward: 0.86, Epsilon: 0.100\n",
            "Episode 7300, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 7400, P1 reward: -0.11, P2 reward: 0.90, Epsilon: 0.100\n",
            "Episode 7500, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 7600, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 7700, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 7800, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 7900, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 8000, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 8100, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 8200, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 8300, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 8400, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 8500, P1 reward: -0.20, P2 reward: 0.81, Epsilon: 0.100\n",
            "Episode 8600, P1 reward: -0.13, P2 reward: 0.88, Epsilon: 0.100\n",
            "Episode 8700, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 8800, P1 reward: -0.20, P2 reward: 0.81, Epsilon: 0.100\n",
            "Episode 8900, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 9000, P1 reward: -0.11, P2 reward: 0.90, Epsilon: 0.100\n",
            "Episode 9100, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 9200, P1 reward: -0.20, P2 reward: 0.81, Epsilon: 0.100\n",
            "Episode 9300, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 9400, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 9500, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 9600, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.100\n",
            "Episode 9700, P1 reward: -0.20, P2 reward: 0.81, Epsilon: 0.100\n",
            "Episode 9800, P1 reward: -0.21, P2 reward: -0.20, Epsilon: 0.100\n",
            "Episode 9900, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 10000, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 10100, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 10200, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 10300, P1 reward: -0.21, P2 reward: 0.80, Epsilon: 0.100\n",
            "Episode 10400, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.100\n",
            "Episode 10500, P1 reward: -0.20, P2 reward: 0.81, Epsilon: 0.100\n",
            "Episode 10600, P1 reward: -0.20, P2 reward: 0.81, Epsilon: 0.100\n",
            "Episode 10700, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 10800, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 10900, P1 reward: -0.21, P2 reward: -0.20, Epsilon: 0.100\n",
            "Episode 11000, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 11100, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 11200, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 11300, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 11400, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 11500, P1 reward: -0.13, P2 reward: 0.88, Epsilon: 0.100\n",
            "Episode 11600, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 11700, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.100\n",
            "Episode 11800, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 11900, P1 reward: 0.90, P2 reward: -0.10, Epsilon: 0.100\n",
            "Episode 12000, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 12100, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 12200, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 12300, P1 reward: -0.20, P2 reward: 0.81, Epsilon: 0.100\n",
            "Episode 12400, P1 reward: 0.90, P2 reward: -0.10, Epsilon: 0.100\n",
            "Episode 12500, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 12600, P1 reward: 0.89, P2 reward: -0.11, Epsilon: 0.100\n",
            "Episode 12700, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 12800, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 12900, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.100\n",
            "Episode 13000, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 13100, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 13200, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 13300, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.100\n",
            "Episode 13400, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 13500, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 13600, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.100\n",
            "Episode 13700, P1 reward: 0.87, P2 reward: -0.13, Epsilon: 0.100\n",
            "Episode 13800, P1 reward: 0.89, P2 reward: -0.11, Epsilon: 0.100\n",
            "Episode 13900, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 14000, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 14100, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 14200, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 14300, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 14400, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 14500, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 14600, P1 reward: 0.80, P2 reward: -0.20, Epsilon: 0.100\n",
            "Episode 14700, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 14800, P1 reward: -0.20, P2 reward: 0.81, Epsilon: 0.100\n",
            "Episode 14900, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 15000, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.100\n",
            "Episode 15100, P1 reward: -0.14, P2 reward: 0.87, Epsilon: 0.100\n",
            "Episode 15200, P1 reward: 0.87, P2 reward: -0.13, Epsilon: 0.100\n",
            "Episode 15300, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 15400, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 15500, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 15600, P1 reward: -0.13, P2 reward: 0.88, Epsilon: 0.100\n",
            "Episode 15700, P1 reward: -0.14, P2 reward: 0.87, Epsilon: 0.100\n",
            "Episode 15800, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 15900, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 16000, P1 reward: -0.15, P2 reward: 0.86, Epsilon: 0.100\n",
            "Episode 16100, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 16200, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 16300, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.100\n",
            "Episode 16400, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 16500, P1 reward: 0.91, P2 reward: -0.09, Epsilon: 0.100\n",
            "Episode 16600, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.100\n",
            "Episode 16700, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 16800, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 16900, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.100\n",
            "Episode 17000, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 17100, P1 reward: -0.21, P2 reward: -0.20, Epsilon: 0.100\n",
            "Episode 17200, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 17300, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 17400, P1 reward: 0.90, P2 reward: -0.10, Epsilon: 0.100\n",
            "Episode 17500, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 17600, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 17700, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 17800, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 17900, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 18000, P1 reward: 0.86, P2 reward: -0.14, Epsilon: 0.100\n",
            "Episode 18100, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.100\n",
            "Episode 18200, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 18300, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 18400, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 18500, P1 reward: -0.20, P2 reward: 0.81, Epsilon: 0.100\n",
            "Episode 18600, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 18700, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 18800, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 18900, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 19000, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 19100, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 19200, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 19300, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 19400, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 19500, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 19600, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 19700, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 19800, P1 reward: -0.14, P2 reward: 0.87, Epsilon: 0.100\n",
            "Episode 19900, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 20000, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 20100, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 20200, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 20300, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 20400, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 20500, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.100\n",
            "Episode 20600, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 20700, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 20800, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 20900, P1 reward: 0.80, P2 reward: -0.20, Epsilon: 0.100\n",
            "Episode 21000, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 21100, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 21200, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 21300, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 21400, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 21500, P1 reward: 0.95, P2 reward: -0.05, Epsilon: 0.100\n",
            "Episode 21600, P1 reward: -0.13, P2 reward: 0.88, Epsilon: 0.100\n",
            "Episode 21700, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.100\n",
            "Episode 21800, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 21900, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 22000, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 22100, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 22200, P1 reward: -0.14, P2 reward: 0.87, Epsilon: 0.100\n",
            "Episode 22300, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 22400, P1 reward: 0.84, P2 reward: -0.16, Epsilon: 0.100\n",
            "Episode 22500, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 22600, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 22700, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.100\n",
            "Episode 22800, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 22900, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 23000, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 23100, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 23200, P1 reward: -0.04, P2 reward: 0.97, Epsilon: 0.100\n",
            "Episode 23300, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 23400, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 23500, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 23600, P1 reward: 0.80, P2 reward: -0.20, Epsilon: 0.100\n",
            "Episode 23700, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 23800, P1 reward: -0.15, P2 reward: 0.86, Epsilon: 0.100\n",
            "Episode 23900, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 24000, P1 reward: 0.91, P2 reward: -0.09, Epsilon: 0.100\n",
            "Episode 24100, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 24200, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 24300, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 24400, P1 reward: -0.04, P2 reward: 0.97, Epsilon: 0.100\n",
            "Episode 24500, P1 reward: 0.89, P2 reward: -0.11, Epsilon: 0.100\n",
            "Episode 24600, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 24700, P1 reward: -0.15, P2 reward: 0.86, Epsilon: 0.100\n",
            "Episode 24800, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 24900, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 25000, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 25100, P1 reward: 0.89, P2 reward: -0.11, Epsilon: 0.100\n",
            "Episode 25200, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.100\n",
            "Episode 25300, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 25400, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 25500, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.100\n",
            "Episode 25600, P1 reward: 0.84, P2 reward: -0.16, Epsilon: 0.100\n",
            "Episode 25700, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 25800, P1 reward: -0.15, P2 reward: 0.86, Epsilon: 0.100\n",
            "Episode 25900, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 26000, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 26100, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 26200, P1 reward: -0.21, P2 reward: 0.80, Epsilon: 0.100\n",
            "Episode 26300, P1 reward: 0.86, P2 reward: -0.14, Epsilon: 0.100\n",
            "Episode 26400, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 26500, P1 reward: 0.84, P2 reward: -0.16, Epsilon: 0.100\n",
            "Episode 26600, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 26700, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.100\n",
            "Episode 26800, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 26900, P1 reward: 0.84, P2 reward: -0.16, Epsilon: 0.100\n",
            "Episode 27000, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 27100, P1 reward: 0.84, P2 reward: -0.16, Epsilon: 0.100\n",
            "Episode 27200, P1 reward: 0.84, P2 reward: -0.16, Epsilon: 0.100\n",
            "Episode 27300, P1 reward: 0.80, P2 reward: -0.20, Epsilon: 0.100\n",
            "Episode 27400, P1 reward: 0.86, P2 reward: -0.14, Epsilon: 0.100\n",
            "Episode 27500, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 27600, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.100\n",
            "Episode 27700, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 27800, P1 reward: 0.87, P2 reward: -0.13, Epsilon: 0.100\n",
            "Episode 27900, P1 reward: 0.87, P2 reward: -0.13, Epsilon: 0.100\n",
            "Episode 28000, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 28100, P1 reward: -0.13, P2 reward: 0.88, Epsilon: 0.100\n",
            "Episode 28200, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 28300, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.100\n",
            "Episode 28400, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 28500, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.100\n",
            "Episode 28600, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 28700, P1 reward: 0.90, P2 reward: -0.10, Epsilon: 0.100\n",
            "Episode 28800, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.100\n",
            "Episode 28900, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 29000, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 29100, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 29200, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 29300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 29400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 29500, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 29600, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 29700, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 29800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 29900, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 30000, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 30100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 30200, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 30300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 30400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 30500, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 30600, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 30700, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 30800, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 30900, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 31000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 31100, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 31200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 31300, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 31400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 31500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 31600, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 31700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 31800, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 31900, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 32000, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 32100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 32200, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 32300, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.100\n",
            "Episode 32400, P1 reward: 0.87, P2 reward: -0.13, Epsilon: 0.100\n",
            "Episode 32500, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 32600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 32700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 32800, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 32900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 33000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 33100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 33200, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 33300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 33400, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 33500, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 33600, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 33700, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 33800, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 33900, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 34000, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 34100, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 34200, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 34300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 34400, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 34500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 34600, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 34700, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 34800, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 34900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 35000, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 35100, P1 reward: -0.12, P2 reward: 0.89, Epsilon: 0.100\n",
            "Episode 35200, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 35300, P1 reward: -0.13, P2 reward: 0.88, Epsilon: 0.100\n",
            "Episode 35400, P1 reward: -0.13, P2 reward: 0.88, Epsilon: 0.100\n",
            "Episode 35500, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 35600, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 35700, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 35800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 35900, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 36000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 36100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 36200, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 36300, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 36400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 36500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 36600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 36700, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 36800, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 36900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 37000, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 37100, P1 reward: 0.89, P2 reward: -0.11, Epsilon: 0.100\n",
            "Episode 37200, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 37300, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 37400, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.100\n",
            "Episode 37500, P1 reward: 0.81, P2 reward: -0.19, Epsilon: 0.100\n",
            "Episode 37600, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 37700, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 37800, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 37900, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 38000, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 38100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 38200, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 38300, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 38400, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 38500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 38600, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 38700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 38800, P1 reward: 0.91, P2 reward: -0.09, Epsilon: 0.100\n",
            "Episode 38900, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 39000, P1 reward: -0.15, P2 reward: 0.86, Epsilon: 0.100\n",
            "Episode 39100, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 39200, P1 reward: 0.86, P2 reward: -0.14, Epsilon: 0.100\n",
            "Episode 39300, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 39400, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 39500, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 39600, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 39700, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 39800, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 39900, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 40000, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 40100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 40200, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 40300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 40400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 40500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 40600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 40700, P1 reward: -0.15, P2 reward: 0.86, Epsilon: 0.100\n",
            "Episode 40800, P1 reward: -0.20, P2 reward: 0.81, Epsilon: 0.100\n",
            "Episode 40900, P1 reward: -0.15, P2 reward: 0.86, Epsilon: 0.100\n",
            "Episode 41000, P1 reward: -0.15, P2 reward: 0.86, Epsilon: 0.100\n",
            "Episode 41100, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.100\n",
            "Episode 41200, P1 reward: 0.90, P2 reward: -0.10, Epsilon: 0.100\n",
            "Episode 41300, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.100\n",
            "Episode 41400, P1 reward: 0.89, P2 reward: -0.11, Epsilon: 0.100\n",
            "Episode 41500, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 41600, P1 reward: 0.84, P2 reward: -0.16, Epsilon: 0.100\n",
            "Episode 41700, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 41800, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 41900, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 42000, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 42100, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 42200, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 42300, P1 reward: 0.91, P2 reward: -0.09, Epsilon: 0.100\n",
            "Episode 42400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 42500, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 42600, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 42700, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 42800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 42900, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 43000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 43100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 43200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 43300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 43400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 43500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 43600, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 43700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 43800, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 43900, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 44000, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 44100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 44200, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 44300, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 44400, P1 reward: -0.12, P2 reward: 0.89, Epsilon: 0.100\n",
            "Episode 44500, P1 reward: 0.90, P2 reward: -0.10, Epsilon: 0.100\n",
            "Episode 44600, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 44700, P1 reward: 0.91, P2 reward: -0.09, Epsilon: 0.100\n",
            "Episode 44800, P1 reward: 0.89, P2 reward: -0.11, Epsilon: 0.100\n",
            "Episode 44900, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.100\n",
            "Episode 45000, P1 reward: -0.15, P2 reward: 0.86, Epsilon: 0.100\n",
            "Episode 45100, P1 reward: -0.15, P2 reward: 0.86, Epsilon: 0.100\n",
            "Episode 45200, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.100\n",
            "Episode 45300, P1 reward: -0.15, P2 reward: 0.86, Epsilon: 0.100\n",
            "Episode 45400, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 45500, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.100\n",
            "Episode 45600, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 45700, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.100\n",
            "Episode 45800, P1 reward: 0.86, P2 reward: -0.14, Epsilon: 0.100\n",
            "Episode 45900, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 46000, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 46100, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 46200, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 46300, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 46400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 46500, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 46600, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 46700, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 46800, P1 reward: 0.90, P2 reward: -0.10, Epsilon: 0.100\n",
            "Episode 46900, P1 reward: -0.17, P2 reward: 0.84, Epsilon: 0.100\n",
            "Episode 47000, P1 reward: -0.15, P2 reward: 0.86, Epsilon: 0.100\n",
            "Episode 47100, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 47200, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 47300, P1 reward: 0.84, P2 reward: -0.16, Epsilon: 0.100\n",
            "Episode 47400, P1 reward: 0.87, P2 reward: -0.13, Epsilon: 0.100\n",
            "Episode 47500, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.100\n",
            "Episode 47600, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 47700, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 47800, P1 reward: -0.16, P2 reward: 0.85, Epsilon: 0.100\n",
            "Episode 47900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 48000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 48100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 48200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 48300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 48400, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 48500, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 48600, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 48700, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 48800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 48900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 49000, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 49100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 49200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 49300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 49400, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 49500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 49600, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 49700, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 49800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 49900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 50000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 50100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 50200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 50300, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 50400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 50500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 50600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 50700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 50800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 50900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 51000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 51100, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 51200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 51300, P1 reward: 0.87, P2 reward: -0.13, Epsilon: 0.100\n",
            "Episode 51400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 51500, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 51600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 51700, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 51800, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 51900, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 52000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 52100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 52200, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 52300, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 52400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 52500, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 52600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 52700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 52800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 52900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 53000, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 53100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 53200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 53300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 53400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 53500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 53600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 53700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 53800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 53900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 54000, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 54100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 54200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 54300, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 54400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 54500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 54600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 54700, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 54800, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 54900, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 55000, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 55100, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 55200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 55300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 55400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 55500, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 55600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 55700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 55800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 55900, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 56000, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 56100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 56200, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 56300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 56400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 56500, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 56600, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 56700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 56800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 56900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 57000, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 57100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 57200, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 57300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 57400, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 57500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 57600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 57700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 57800, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 57900, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 58000, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 58100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 58200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 58300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 58400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 58500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 58600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 58700, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 58800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 58900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 59000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 59100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 59200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 59300, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 59400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 59500, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 59600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 59700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 59800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 59900, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 60000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 60100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 60200, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 60300, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 60400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 60500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 60600, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 60700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 60800, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 60900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 61000, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 61100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 61200, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 61300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 61400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 61500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 61600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 61700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 61800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 61900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 62000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 62100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 62200, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 62300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 62400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 62500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 62600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 62700, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 62800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 62900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 63000, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 63100, P1 reward: 0.89, P2 reward: -0.11, Epsilon: 0.100\n",
            "Episode 63200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 63300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 63400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 63500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 63600, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 63700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 63800, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 63900, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 64000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 64100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 64200, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 64300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 64400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 64500, P1 reward: 0.95, P2 reward: -0.05, Epsilon: 0.100\n",
            "Episode 64600, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 64700, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 64800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 64900, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 65000, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 65100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 65200, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 65300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 65400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 65500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 65600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 65700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 65800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 65900, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 66000, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 66100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 66200, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 66300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 66400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 66500, P1 reward: 0.85, P2 reward: -0.15, Epsilon: 0.100\n",
            "Episode 66600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 66700, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 66800, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 66900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 67000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 67100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 67200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 67300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 67400, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 67500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 67600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 67700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 67800, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 67900, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 68000, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 68100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 68200, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 68300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 68400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 68500, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 68600, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 68700, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 68800, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 68900, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 69000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 69100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 69200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 69300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 69400, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 69500, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 69600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 69700, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 69800, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 69900, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 70000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 70100, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 70200, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 70300, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 70400, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 70500, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 70600, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 70700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 70800, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 70900, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 71000, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 71100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 71200, P1 reward: 0.95, P2 reward: -0.05, Epsilon: 0.100\n",
            "Episode 71300, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 71400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 71500, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 71600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 71700, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 71800, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 71900, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 72000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 72100, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 72200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 72300, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 72400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 72500, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 72600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 72700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 72800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 72900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 73000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 73100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 73200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 73300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 73400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 73500, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 73600, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 73700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 73800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 73900, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 74000, P1 reward: 0.82, P2 reward: -0.18, Epsilon: 0.100\n",
            "Episode 74100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 74200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 74300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 74400, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 74500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 74600, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 74700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 74800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 74900, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 75000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 75100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 75200, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 75300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 75400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 75500, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 75600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 75700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 75800, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 75900, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 76000, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 76100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 76200, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 76300, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 76400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 76500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 76600, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 76700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 76800, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 76900, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 77000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 77100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 77200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 77300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 77400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 77500, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 77600, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 77700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 77800, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 77900, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 78000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 78100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 78200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 78300, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 78400, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 78500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 78600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 78700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 78800, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 78900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 79000, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 79100, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 79200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 79300, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 79400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 79500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 79600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 79700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 79800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 79900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 80000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 80100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 80200, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 80300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 80400, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 80500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 80600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 80700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 80800, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 80900, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 81000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 81100, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 81200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 81300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 81400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 81500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 81600, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 81700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 81800, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 81900, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 82000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 82100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 82200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 82300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 82400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 82500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 82600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 82700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 82800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 82900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 83000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 83100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 83200, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 83300, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 83400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 83500, P1 reward: 0.95, P2 reward: -0.05, Epsilon: 0.100\n",
            "Episode 83600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 83700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 83800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 83900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 84000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 84100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 84200, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 84300, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 84400, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 84500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 84600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 84700, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 84800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 84900, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 85000, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 85100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 85200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 85300, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 85400, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 85500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 85600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 85700, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 85800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 85900, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 86000, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 86100, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 86200, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 86300, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 86400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 86500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 86600, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 86700, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 86800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 86900, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 87000, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 87100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 87200, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 87300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 87400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 87500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 87600, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 87700, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 87800, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 87900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 88000, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 88100, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 88200, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 88300, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 88400, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 88500, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 88600, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 88700, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 88800, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 88900, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 89000, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 89100, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 89200, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 89300, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 89400, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 89500, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 89600, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 89700, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 89800, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 89900, P1 reward: -0.11, P2 reward: 0.90, Epsilon: 0.100\n",
            "Episode 90000, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 90100, P1 reward: 0.91, P2 reward: -0.09, Epsilon: 0.100\n",
            "Episode 90200, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 90300, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 90400, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.100\n",
            "Episode 90500, P1 reward: -0.09, P2 reward: 0.92, Epsilon: 0.100\n",
            "Episode 90600, P1 reward: 0.90, P2 reward: -0.10, Epsilon: 0.100\n",
            "Episode 90700, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.100\n",
            "Episode 90800, P1 reward: -0.10, P2 reward: 0.91, Epsilon: 0.100\n",
            "Episode 90900, P1 reward: 0.91, P2 reward: -0.09, Epsilon: 0.100\n",
            "Episode 91000, P1 reward: -0.11, P2 reward: 0.90, Epsilon: 0.100\n",
            "Episode 91100, P1 reward: 0.87, P2 reward: -0.13, Epsilon: 0.100\n",
            "Episode 91200, P1 reward: 0.89, P2 reward: -0.11, Epsilon: 0.100\n",
            "Episode 91300, P1 reward: 0.87, P2 reward: -0.13, Epsilon: 0.100\n",
            "Episode 91400, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 91500, P1 reward: 0.89, P2 reward: -0.11, Epsilon: 0.100\n",
            "Episode 91600, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 91700, P1 reward: 0.88, P2 reward: -0.12, Epsilon: 0.100\n",
            "Episode 91800, P1 reward: -0.13, P2 reward: 0.88, Epsilon: 0.100\n",
            "Episode 91900, P1 reward: -0.18, P2 reward: 0.83, Epsilon: 0.100\n",
            "Episode 92000, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 92100, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 92200, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 92300, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 92400, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 92500, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 92600, P1 reward: -0.19, P2 reward: 0.82, Epsilon: 0.100\n",
            "Episode 92700, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 92800, P1 reward: -0.06, P2 reward: 0.95, Epsilon: 0.100\n",
            "Episode 92900, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 93000, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 93100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 93200, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 93300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 93400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 93500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 93600, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 93700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 93800, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 93900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 94000, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 94100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 94200, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 94300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 94400, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 94500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 94600, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 94700, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 94800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 94900, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 95000, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 95100, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 95200, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 95300, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 95400, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 95500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 95600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 95700, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 95800, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 95900, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 96000, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 96100, P1 reward: 0.92, P2 reward: -0.08, Epsilon: 0.100\n",
            "Episode 96200, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 96300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 96400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 96500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 96600, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 96700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 96800, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 96900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 97000, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 97100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 97200, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 97300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 97400, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 97500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 97600, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 97700, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 97800, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 97900, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 98000, P1 reward: 0.83, P2 reward: -0.17, Epsilon: 0.100\n",
            "Episode 98100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 98200, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 98300, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 98400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 98500, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 98600, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 98700, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 98800, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 98900, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 99000, P1 reward: -0.08, P2 reward: 0.93, Epsilon: 0.100\n",
            "Episode 99100, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 99200, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 99300, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n",
            "Episode 99400, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 99500, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 99600, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 99700, P1 reward: 0.93, P2 reward: -0.07, Epsilon: 0.100\n",
            "Episode 99800, P1 reward: 0.94, P2 reward: -0.06, Epsilon: 0.100\n",
            "Episode 99900, P1 reward: -0.07, P2 reward: 0.94, Epsilon: 0.100\n"
          ]
        }
      ],
      "source": [
        "trained_model1, trained_model2 = train_self_play(episodes=100000,epsilon_decay=0.9995)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_model(model, path):\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f\"Model saved to {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'trained_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m save_model(\u001b[43mtrained_model\u001b[49m)\n",
            "\u001b[31mNameError\u001b[39m: name 'trained_model' is not defined"
          ]
        }
      ],
      "source": [
        "save_model(trained_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_trained_model(path=\"connect4_model_weights.pth\"):\n",
        "    model = DQN().to(device)\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    print(f\"Loaded model from {path}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model from connect4_dqn_ep10000.pth\n"
          ]
        }
      ],
      "source": [
        "trained_model = load_trained_model(path=\"connect4_dqn_ep10000.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32aOgNMqOSDp"
      },
      "source": [
        "Playing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGqA-mdHOTFx"
      },
      "outputs": [],
      "source": [
        "def play_against_model(starting_player=None):\n",
        "    model_choice = input(\"Play against model 1 (X) or model 2 (O)? Enter 1 or 2: \").strip()\n",
        "    model_path = \"connect4_model1_ep10000.pth\" if model_choice == \"1\" else \"connect4_model2_ep10000.pth\"\n",
        "    model = DQN().to(device)\n",
        "    env = Connect4Env()\n",
        "\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    if starting_player is None:\n",
        "        choice = input(\"Do you want to go first? (y/n): \").lower()\n",
        "        if choice == 'y':\n",
        "            env.current_player = -1\n",
        "        else:\n",
        "            env.current_player = 1\n",
        "    else:\n",
        "        env.current_player = -1 if starting_player == -1 else 1\n",
        "    print(\"You are Player -1 (O). Model is Player 1 (X). Columns: 0 to 6\")\n",
        "    print(f\"Playing against model from: {model_path}\")\n",
        "    print(env.board)\n",
        "\n",
        "    while not done:\n",
        "        if env.current_player == -1:\n",
        "            try:\n",
        "                user_action = int(input(\"Your move (0-6): \"))\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Try a number from 0 to 6.\")\n",
        "                continue\n",
        "            if user_action not in env.valid_actions():\n",
        "                print(\"Invalid move. Try again.\")\n",
        "                continue\n",
        "            state, reward, done, _ = env.step(user_action)\n",
        "        else:\n",
        "            valid_actions = env.valid_actions()\n",
        "            action = select_action(model, state, epsilon=0.0, valid_actions=valid_actions)\n",
        "            state, reward, done, _ = env.step(action)\n",
        "            print(\"Model played column:\", action)\n",
        "\n",
        "        # Always print board after any move\n",
        "        symbol_map = {1: 'X', -1: 'O', 0: '.'}\n",
        "        print(\"\\nCurrent board:\")\n",
        "        for row in env.board:\n",
        "            print(' '.join(symbol_map[cell] for cell in row))\n",
        "        print()\n",
        "\n",
        "        if done:\n",
        "            print(\"Game Over. Reward:\", reward)\n",
        "            break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scFE5r_6ObKi",
        "outputId": "f2b45771-82e3-4fd7-aec4-8dccf6e35df5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ajmat\\AppData\\Local\\Temp\\ipykernel_77264\\1160430533.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are Player -1 (O). Model is Player 1 (X). Columns: 0 to 6\n",
            "Playing against model from: connect4_model2_final.pth\n",
            "[[0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n",
            "\n",
            "Current board:\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . O . . .\n",
            "\n",
            "Model played column: 6\n",
            "\n",
            "Current board:\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . O . . X\n",
            "\n",
            "\n",
            "Current board:\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . O . . .\n",
            ". . . O . . X\n",
            "\n",
            "Model played column: 6\n",
            "\n",
            "Current board:\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . O . . X\n",
            ". . . O . . X\n",
            "\n",
            "\n",
            "Current board:\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . O . . .\n",
            ". . . O . . X\n",
            ". . . O . . X\n",
            "\n",
            "Model played column: 6\n",
            "\n",
            "Current board:\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . O . . X\n",
            ". . . O . . X\n",
            ". . . O . . X\n",
            "\n",
            "\n",
            "Current board:\n",
            ". . . . . . .\n",
            ". . . . . . .\n",
            ". . . O . . .\n",
            ". . . O . . X\n",
            ". . . O . . X\n",
            ". . . O . . X\n",
            "\n",
            "Game Over. Reward: 1\n"
          ]
        }
      ],
      "source": [
        "play_against_model()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
