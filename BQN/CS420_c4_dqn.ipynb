{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP1z7GIGl1ve"
      },
      "source": [
        "# Reinforcement Learning with Convolutional Neural Network\n",
        "\n",
        "This notebook demonstrates a basic Deep Q-Network (DQN) style reinforcement learning setup with a convolutional neural network (CNN) as the Q-function approximator.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## General Considerations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ⚠️ Run this notebook **locally**, not in Colab. Audio processing with `ffmpeg` does **not** work in Colab. Additionally, the models and metrics routing is based on the repo relative locations, so make sure to **clone** the Repo\n",
        "\n",
        "1. Clone this repo.\n",
        "2. Install dependencies, including `ffmpeg`:\n",
        "   ```bash\n",
        "   brew install ffmpeg  # for macOS\n",
        "   ```\n",
        "3. Open the notebook locally. Set `TRAIN_MODEL = True` to retrain, or `False` to use the provided model (in `/models/`) and metrics (in `/metrics/`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_MODEL = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just check weather `ffmpeg` is installed or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/bin/ffmpeg\n"
          ]
        }
      ],
      "source": [
        "!which ffmpeg || echo \"FFmpeg not found!\" # else install it using e.g. brew install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duSA10BUl7Hf"
      },
      "source": [
        "## 1. Setup and Imports\n",
        "\n",
        "Import necessary libraries and set up the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJpypK1Al-Hw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "import random\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import time\n",
        "import io\n",
        "import re\n",
        "import tempfile\n",
        "from contextlib import suppress\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGdR_jidmC_7"
      },
      "source": [
        "Device configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXnfMDVrmEcV",
        "outputId": "cdb44bc2-74f1-40e1-bdc8-a2914d802d3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "if device.type == \"cuda\":\n",
        "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXELUdhbmGRF"
      },
      "source": [
        "## 2. Define the Convolutional Q-Network\n",
        "\n",
        "A simple CNN that takes in a board and outputs Q-values for each action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RmPtrlkUmNgg"
      },
      "outputs": [],
      "source": [
        "class ConvQNetwork(nn.Module):\n",
        "    def __init__(self, input_shape=(1,6,7), num_actions=7):\n",
        "        super().__init__()\n",
        "        c, h, w = input_shape\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(c, 32, kernel_size=(3,3), stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=(3,3), stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        conv_out_size = self._get_conv_out(input_shape)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(conv_out_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_actions)\n",
        "        )\n",
        "\n",
        "    def _get_conv_out(self, shape):\n",
        "        o = self.conv(torch.zeros(1, *shape))\n",
        "        return int(np.prod(o.size()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv_out = self.conv(x).view(x.size(0), -1)\n",
        "        return self.fc(conv_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN0370nprBZR"
      },
      "source": [
        "# Define Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This class defines a Connect 4 environment tailored for reinforcement learning using OpenAI Gym. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vgtT1NDrAEy"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "class BoardEnv(gym.Env):\n",
        "\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Observation: 6×7 matrix with values in {-1, 0, +1}\n",
        "        self.observation_space = spaces.Box(low=-1, high=1, shape=(6,7), dtype=np.int8)\n",
        "        # Actions: drop in one of 7 columns\n",
        "        self.action_space = spaces.Discrete(7)\n",
        "\n",
        "        self.state = {}\n",
        "        self.current_player = +1\n",
        "\n",
        "    def reset(self):\n",
        "        board = np.zeros((6,7), dtype=np.int8)\n",
        "        self.state[\"board\"] = board\n",
        "        self.state[\"move-sequence\"] = \"\"\n",
        "        self.current_player = +1\n",
        "        # Return a fresh copy for safety:\n",
        "        return {\"board\": board.copy(),\n",
        "                \"move-sequence\": self.state[\"move-sequence\"]}\n",
        "\n",
        "    def _get_action_reward(self, sequence, action):\n",
        "      scores = [0] * 7\n",
        "      # GET request\n",
        "      response = requests.get('https://ludolab.net/solve/connect4?position=' + sequence)\n",
        "      for score in response.json():\n",
        "          scores[int(score['move'])-1] = score['score']\n",
        "      return (scores[action]+20)/40\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        action: integer 0–6, the column to drop your piece into.\n",
        "        Returns: (next_state, reward, done, info)\n",
        "        \"\"\"\n",
        "        # 1) Check legality\n",
        "        if not self._is_valid_action(action):\n",
        "            # Illegal move: immediate loss\n",
        "            return {\"board\": self.state[\"board\"].copy(), \"move-sequence\": self.state[\"move-sequence\"]}, -1.0, True, {\"illegal_move\": True}\n",
        "\n",
        "        # 2) Apply move\n",
        "        row = self._get_drop_row(action)\n",
        "        self.state[\"board\"][row, action] = self.current_player\n",
        "        reward = self._get_action_reward(self.state[\"move-sequence\"], action)\n",
        "        self.state[\"move-sequence\"] += str(action+1)\n",
        "\n",
        "        # 3) Check for win\n",
        "        if self._check_win(self.state[\"board\"], action, self.current_player):\n",
        "            return {\"board\": self.state[\"board\"].copy(), \"move-sequence\": self.state[\"move-sequence\"]}, reward, True, {}\n",
        "\n",
        "        # 4) Check for draw\n",
        "        if np.all(self.state[\"board\"] != 0):\n",
        "            return {\"board\": self.state[\"board\"].copy(), \"move-sequence\": self.state[\"move-sequence\"]}, reward, True, {\"draw\": True}\n",
        "\n",
        "        # 5) Otherwise, game continues\n",
        "        self.current_player *= -1\n",
        "        return {\"board\": self.state[\"board\"].copy(), \"move-sequence\": self.state[\"move-sequence\"]}, reward, False, {}\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        # Simple text render\n",
        "        print(self.state[\"board\"])\n",
        "\n",
        "    def _is_valid_action(self, action):\n",
        "        return 0 <= action < 7 and self.state[\"board\"][0, action] == 0\n",
        "\n",
        "    def _get_drop_row(self, action):\n",
        "        # Find the lowest empty row in the chosen column\n",
        "        col = self.state[\"board\"][:, action]\n",
        "        empties = np.where(col == 0)[0]\n",
        "        return empties[-1]\n",
        "\n",
        "    def _check_win(self, board: np.ndarray, action: int, player: int) -> bool:\n",
        "      \"\"\"\n",
        "      Check for a four-in-a-row involving the most recent move in column `action`\n",
        "      by `player` (±1). Returns True if that move created a win.\n",
        "      \"\"\"\n",
        "      rows, cols = board.shape\n",
        "\n",
        "      # 1) Find the row index where the last piece landed\n",
        "      col_vals = board[:, action]\n",
        "      # indices where the board equals the player in that column\n",
        "      player_positions = np.where(col_vals == player)[0]\n",
        "      row = player_positions[0]\n",
        "\n",
        "      # 2) Define a helper to count in one direction\n",
        "      def count_dir(dr: int, dc: int) -> int:\n",
        "          r, c = row + dr, action + dc\n",
        "          count = 0\n",
        "          while 0 <= r < rows and 0 <= c < cols and board[r, c] == player:\n",
        "              count += 1\n",
        "              r += dr\n",
        "              c += dc\n",
        "          return count\n",
        "\n",
        "      # 3) Check horizontal (← & →)\n",
        "      horiz = 1 + count_dir(0, -1) + count_dir(0, +1)\n",
        "      if horiz >= 4:\n",
        "          return True\n",
        "\n",
        "      # 4) Check vertical\n",
        "      vert = 1 + count_dir(1, 0) + count_dir(-1, 0)\n",
        "      if vert >= 4:\n",
        "          return True\n",
        "\n",
        "      # 5) Check diagonal up-right / down-left\n",
        "      diag1 = 1 + count_dir(-1, +1) + count_dir(+1, -1)\n",
        "      if diag1 >= 4:\n",
        "          return True\n",
        "\n",
        "      # 6) Check diagonal up-left / down-right\n",
        "      diag2 = 1 + count_dir(-1, -1) + count_dir(+1, +1)\n",
        "      if diag2 >= 4:\n",
        "          return True\n",
        "\n",
        "      return False\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WudQm_cumhxC"
      },
      "source": [
        "## 3. Replay Buffer\n",
        "\n",
        "A simple replay buffer to store and sample transitions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "78DGmKS3mjPw"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "        states, actions, rewards, next_states, dones = zip(*batch)\n",
        "        return (\n",
        "            np.stack(states),\n",
        "            np.array(actions),\n",
        "            np.array(rewards, dtype=np.float32),\n",
        "            np.stack(next_states),\n",
        "            np.array(dones, dtype=np.uint8)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INs43yakpVkD"
      },
      "source": [
        "## Illegal Moves Mask Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5N3SRXiMpYmq"
      },
      "outputs": [],
      "source": [
        "def get_illegal_moves_mask(state):\n",
        "    \"\"\"\n",
        "    Given a board state (6×7 numpy array with 0=empty, ±1=player tokens),\n",
        "    return a boolean list of length 7 where True indicates the column is full/illegal.\n",
        "    \"\"\"\n",
        "    mask = [False] * 7\n",
        "    # Top row index 0 corresponds to the highest (first-placed) slot in each column\n",
        "    for col in range(7):\n",
        "        if state[0, col] != 0:\n",
        "            mask[col] = True\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8cOLXthqjik"
      },
      "source": [
        "# Epsilon Decay Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "68WbAkYiqmn2"
      },
      "outputs": [],
      "source": [
        "def get_epsilon(start, end, period, step):\n",
        "    # linearly anneal from start → end over decay_steps\n",
        "    fraction = min(step / period, 1.0)\n",
        "    return start + fraction * (end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHgy4oaWmqaa"
      },
      "source": [
        "## 4. Training Loop\n",
        "\n",
        "A basic training loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nil7zA0Xmr5s",
        "outputId": "d6b4e214-c61c-4881-93fa-d6df2b518ce5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "if TRAIN_MODEL == True:\n",
        "  # create a log directory\n",
        "  timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "  log_dir = f\"runs/c4_dqn_{timestamp}\"\n",
        "  checkpoint_dir = f\"checkpoints/c4_dqn_{timestamp}\"\n",
        "  os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "  os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "  # instantiate the writer\n",
        "  writer = SummaryWriter(log_dir)\n",
        "  print(f\"Logging to: {log_dir}\")\n",
        "\n",
        "  # Hyperparameters\n",
        "  learning_rate = 1e-4\n",
        "  gamma = 0.99\n",
        "  buffer_capacity = 3000\n",
        "  batch_size = 32\n",
        "  sync_target_steps = 1000\n",
        "  num_episodes = 500\n",
        "\n",
        "  env = BoardEnv()\n",
        "\n",
        "  # Initialize networks and optimizer\n",
        "  policy_net1 = ConvQNetwork(input_shape=(1, 6, 7), num_actions=7).to(device)\n",
        "  target_net1 = ConvQNetwork(input_shape=(1, 6, 7), num_actions=7).to(device)\n",
        "  target_net1.load_state_dict(policy_net1.state_dict())\n",
        "  optimizer1 = optim.Adam(policy_net1.parameters(), lr=learning_rate)\n",
        "  replay_buffer1 = ReplayBuffer(buffer_capacity)\n",
        "\n",
        "  policy_net2 = ConvQNetwork(input_shape=(1, 6, 7), num_actions=7).to(device)\n",
        "  target_net2 = ConvQNetwork(input_shape=(1, 6, 7), num_actions=7).to(device)\n",
        "  target_net2.load_state_dict(policy_net2.state_dict())\n",
        "  optimizer2 = optim.Adam(policy_net2.parameters(), lr=learning_rate)\n",
        "  replay_buffer2 = ReplayBuffer(buffer_capacity)\n",
        "\n",
        "  steps_done = 0\n",
        "\n",
        "\n",
        "  for episode in range(num_episodes):\n",
        "      state = env.reset()  # obtain initial state\n",
        "      done = False\n",
        "      total_reward1 = 0\n",
        "      total_reward2 = 0\n",
        "      loss1Val = 0\n",
        "      loss2Val = 0\n",
        "\n",
        "      epsilon = get_epsilon(1.0, 0.05, 3000, steps_done)\n",
        "\n",
        "      while not done:\n",
        "          # Select action (epsilon-greedy with action masking)\n",
        "          # Convert current board to tensor\n",
        "          state_tensor = torch.tensor(state[\"board\"], dtype=torch.float32, device=device).unsqueeze(0).unsqueeze(1)  # shape [1,1,6,7]\n",
        "          with torch.no_grad():\n",
        "              qvals = policy_net1(state_tensor)  # shape [1,7]\n",
        "              # Mask out illegal moves (e.g., full columns)\n",
        "              illegal_mask = get_illegal_moves_mask(state[\"board\"])  # bool array of length 7\n",
        "              qvals[0][illegal_mask] = -1e9\n",
        "              # Epsilon-greedy selection among legal actions\n",
        "              if random.random() < epsilon:\n",
        "                  valid_actions = [a for a, illegal in enumerate(illegal_mask) if not illegal]\n",
        "                  action = random.choice(valid_actions)\n",
        "              else:\n",
        "                  action = qvals.argmax(dim=1).item()\n",
        "          # Step environment\n",
        "          try:\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "          except:\n",
        "            action = -1\n",
        "            break\n",
        "\n",
        "\n",
        "          # Compute placeholder reward\n",
        "          total_reward1 += reward\n",
        "\n",
        "          # Store transition\n",
        "          replay_buffer1.push(state[\"board\"], action, reward, next_state[\"board\"], done)\n",
        "\n",
        "          state = next_state\n",
        "\n",
        "          if not done:\n",
        "            #Model2 turn\n",
        "            with torch.no_grad():\n",
        "                qvals = policy_net2(state_tensor)  # shape [1,7]\n",
        "                # Mask out illegal moves (e.g., full columns)\n",
        "                illegal_mask = get_illegal_moves_mask(state[\"board\"])  # bool array of length 7\n",
        "                qvals[0][illegal_mask] = -1e9\n",
        "                # Epsilon-greedy selection among legal actions\n",
        "                if random.random() < epsilon:\n",
        "                    valid_actions = [a for a, illegal in enumerate(illegal_mask) if not illegal]\n",
        "                    action = random.choice(valid_actions)\n",
        "                else:\n",
        "                    action = qvals.argmax(dim=1).item()\n",
        "            # Step environment\n",
        "            try:\n",
        "              next_state, reward, done, _ = env.step(action)\n",
        "            except:\n",
        "              action = -1\n",
        "              break\n",
        "\n",
        "            # Compute placeholder reward\n",
        "            total_reward2 += reward\n",
        "\n",
        "            # Store transition\n",
        "            replay_buffer2.push(state[\"board\"], action, reward, next_state[\"board\"], done)\n",
        "\n",
        "          steps_done += 1\n",
        "\n",
        "          if done and episode % 10 == 0:\n",
        "            env.render()\n",
        "\n",
        "          # Sample and learn\n",
        "          if len(replay_buffer1) >= batch_size:\n",
        "            # 1) Sample a batch\n",
        "            states_b, actions_b, rewards_b, next_states_b, dones_b = replay_buffer1.sample(batch_size)\n",
        "\n",
        "            # 2) Convert to tensors\n",
        "            states_v      = torch.tensor(states_b,      dtype=torch.float32, device=device).unsqueeze(1)   # [B,1,6,7]\n",
        "            actions_v     = torch.tensor(actions_b,     dtype=torch.int64,   device=device).unsqueeze(1)   # [B,1]\n",
        "            rewards_v     = torch.tensor(rewards_b,     dtype=torch.float32, device=device)               # [B]\n",
        "            next_states_v = torch.tensor(next_states_b, dtype=torch.float32, device=device).unsqueeze(1)   # [B,1,6,7]\n",
        "            dones_v       = torch.tensor(dones_b,       dtype=torch.uint8,   device=device)               # [B]\n",
        "\n",
        "            # 3) Compute current Q-values\n",
        "            q_vals = policy_net1(states_v).gather(1, actions_v).squeeze(1)        # [B]\n",
        "\n",
        "            # 4) Compute target Q-values\n",
        "            with torch.no_grad():\n",
        "                # max over next actions (masking illegal moves if desired)\n",
        "                next_q = target_net1(next_states_v).max(1)[0]                     # [B]\n",
        "                target_q = rewards_v + gamma * next_q * (1 - dones_v.float())   # [B]\n",
        "\n",
        "            # 5) Compute loss & backpropagate\n",
        "            loss1 = nn.MSELoss()(q_vals, target_q)\n",
        "\n",
        "            optimizer1.zero_grad()\n",
        "            loss1.backward()\n",
        "            optimizer1.step()\n",
        "            loss1Val = loss1.item()\n",
        "\n",
        "          # Sample and learn\n",
        "          if len(replay_buffer2) >= batch_size:\n",
        "            # 1) Sample a batch\n",
        "            states_b, actions_b, rewards_b, next_states_b, dones_b = replay_buffer2.sample(batch_size)\n",
        "\n",
        "            # 2) Convert to tensors\n",
        "            states_v      = torch.tensor(states_b,      dtype=torch.float32, device=device).unsqueeze(1)   # [B,1,6,7]\n",
        "            actions_v     = torch.tensor(actions_b,     dtype=torch.int64,   device=device).unsqueeze(1)   # [B,1]\n",
        "            rewards_v     = torch.tensor(rewards_b,     dtype=torch.float32, device=device)               # [B]\n",
        "            next_states_v = torch.tensor(next_states_b, dtype=torch.float32, device=device).unsqueeze(1)   # [B,1,6,7]\n",
        "            dones_v       = torch.tensor(dones_b,       dtype=torch.uint8,   device=device)               # [B]\n",
        "\n",
        "            # 3) Compute current Q-values\n",
        "            q_vals = policy_net2(states_v).gather(1, actions_v).squeeze(1)        # [B]\n",
        "\n",
        "            # 4) Compute target Q-values\n",
        "            with torch.no_grad():\n",
        "                # max over next actions (masking illegal moves if desired)\n",
        "                next_q = target_net2(next_states_v).max(1)[0]                     # [B]\n",
        "                target_q = rewards_v + gamma * next_q * (1 - dones_v.float())   # [B]\n",
        "\n",
        "            # 5) Compute loss & backpropagate\n",
        "            loss2 = nn.MSELoss()(q_vals, target_q)\n",
        "\n",
        "            optimizer2.zero_grad()\n",
        "            loss2.backward()\n",
        "            optimizer2.step()\n",
        "            loss2Val = loss2.item()\n",
        "\n",
        "            # Periodically sync target network\n",
        "            if steps_done % sync_target_steps == 0:\n",
        "                target_net1.load_state_dict(policy_net1.state_dict())\n",
        "                target_net2.load_state_dict(policy_net2.state_dict())\n",
        "\n",
        "      writer.add_scalar(\"Rewards/Agent1\", total_reward1, episode)\n",
        "      writer.add_scalar(\"Rewards/Agent2\", total_reward2, episode)\n",
        "\n",
        "      writer.add_scalar(\"Loss/Agent1\", loss1Val, episode)\n",
        "      writer.add_scalar(\"Loss/Agent2\", loss2Val, episode)\n",
        "\n",
        "      writer.add_scalar(\"Epsilon\", epsilon, episode)\n",
        "\n",
        "      print(f\"Episode {episode} - R1: {total_reward1} - R2: {total_reward2} - E: {epsilon} - A {action}\")\n",
        "\n",
        "      if episode % 100 == 0:  # every 100 episodes\n",
        "        torch.save(policy_net1.state_dict(),\n",
        "                  f\"checkpoints/c4_dqn_{timestamp}/policy_net1_ep{episode:04d}.pth\")\n",
        "        torch.save(policy_net2.state_dict(),\n",
        "                  f\"checkpoints/c4_dqn_{timestamp}/policy_net2_ep{episode:04d}.pth\")\n",
        "        print(f\"  → Saved models at episode {episode}\")\n",
        "  episode += 1\n",
        "  torch.save(policy_net1.state_dict(),\n",
        "            f\"checkpoints/c4_dqn_{timestamp}/policy_net1_ep{episode:04d}.pth\")\n",
        "  torch.save(policy_net2.state_dict(),\n",
        "            f\"checkpoints/c4_dqn_{timestamp}/policy_net2_ep{episode:04d}.pth\")\n",
        "  print(f\"  → Saved models at episode {episode}\")\n",
        "  writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## UI Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Connect4UI:\n",
        "    def __init__(self, model_p1, model_p2, ai_player=-1):\n",
        "        # Initialize the game environment\n",
        "        self.env = BoardEnv()\n",
        "        self.model_p1 = model_p1  # Model for player 1 (X)\n",
        "        self.model_p2 = model_p2  # Model for player -1 (O)\n",
        "        self.ai_player = ai_player  # -1 means AI plays as O, 1 means AI plays as X\n",
        "        self.model = self.model_p2 if ai_player == -1 else self.model_p1  # Current model\n",
        "\n",
        "        # Initialize state first\n",
        "        self.state = self.env.reset()\n",
        "        self.done = False\n",
        "        \n",
        "        # Create UI elements\n",
        "        self.create_ui()\n",
        "\n",
        "        # Complete game state initialization\n",
        "        self.update_display()\n",
        "\n",
        "        # If AI goes first, make its move\n",
        "        if self.env.current_player == self.ai_player:\n",
        "            time.sleep(0.5)\n",
        "            self.make_ai_move()\n",
        "\n",
        "    def initialize_game_state(self):\n",
        "        \"\"\"Initialize the game state based on who starts first\"\"\"\n",
        "        # Reset game\n",
        "        self.state = self.env.reset()\n",
        "        self.done = False\n",
        "\n",
        "        # Update display\n",
        "        self.update_display()\n",
        "\n",
        "        # If AI goes first, make its move\n",
        "        if self.env.current_player == self.ai_player:\n",
        "            time.sleep(0.5)\n",
        "            self.make_ai_move()\n",
        "\n",
        "    def create_ui(self):\n",
        "        # Title\n",
        "        self.title = widgets.HTML(value=\"<h1 style='text-align: center;'>Connect 4</h1>\")\n",
        "\n",
        "        # Status message\n",
        "        self.status = widgets.HTML(value=\"<h3 style='text-align: center;'>Game ready! Make your move</h3>\")\n",
        "\n",
        "        # Create buttons for each column\n",
        "        self.buttons = []\n",
        "        for col in range(7):\n",
        "            btn = widgets.Button(description=str(col),\n",
        "                                layout=widgets.Layout(width='60px', height='40px'))\n",
        "            btn.on_click(lambda b, col=col: self.make_move(col))\n",
        "            self.buttons.append(btn)\n",
        "\n",
        "        # Button container (top row)\n",
        "        self.button_container = widgets.HBox(self.buttons,\n",
        "                                           layout=widgets.Layout(justify_content='center'))\n",
        "\n",
        "        # Game board display\n",
        "        self.board_display = widgets.HTML(value=self.render_board_html())\n",
        "\n",
        "        # Add Read Board button\n",
        "        self.read_board_button = widgets.Button(\n",
        "            description=\"Read Board\",\n",
        "            button_style='info',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        )\n",
        "        self.read_board_button.on_click(self.read_board_aloud)\n",
        "        \n",
        "        # Who starts selector\n",
        "        self.player_options = [('You start (X)', 1), ('AI starts (O)', -1)]\n",
        "        self.player_starter = widgets.RadioButtons(\n",
        "            options=self.player_options,\n",
        "            value=-1,  # Default to AI starting\n",
        "            description='New Game:',\n",
        "            layout=widgets.Layout(width='300px')\n",
        "        )\n",
        "\n",
        "        # New Game button\n",
        "        self.new_game_button = widgets.Button(\n",
        "            description=\"Start New Game\",\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        )\n",
        "        self.new_game_button.on_click(self.start_new_game)\n",
        "\n",
        "        # Game controls\n",
        "        self.game_controls = widgets.HBox([\n",
        "            self.player_starter,\n",
        "            self.new_game_button,\n",
        "            self.read_board_button  # Add the Read Board button to the controls\n",
        "        ], layout=widgets.Layout(justify_content='center', margin='20px 0'))\n",
        "\n",
        "        # Add file upload widget for voice commands\n",
        "        self.file_upload = widgets.FileUpload(\n",
        "            accept='',  # Accept all file types\n",
        "            multiple=False,  # Only allow single file upload\n",
        "            description='Voice Command:',\n",
        "            layout=widgets.Layout(width='250px')\n",
        "        )\n",
        "        self.file_upload.observe(self.handle_file_upload, names='value')\n",
        "\n",
        "        # Add submit button for processing the uploaded file\n",
        "        self.submit_button = widgets.Button(\n",
        "            description=\"Process Command\",\n",
        "            button_style='success',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        )\n",
        "        self.submit_button.on_click(self.process_audio_command)\n",
        "\n",
        "        # Audio controls\n",
        "        self.audio_controls = widgets.HBox([\n",
        "            self.file_upload,\n",
        "            self.submit_button\n",
        "        ], layout=widgets.Layout(justify_content='center', margin='10px 0'))\n",
        "\n",
        "        # Add upload status indicator\n",
        "        self.upload_status = widgets.HTML(value=\"<p>No file uploaded</p>\")\n",
        "\n",
        "        # Add status for speech synthesis\n",
        "        self.speech_status = widgets.HTML(value=\"\")\n",
        "\n",
        "        # Combine all widgets\n",
        "        self.app = widgets.VBox([\n",
        "            self.title,\n",
        "            self.status,\n",
        "            self.button_container,\n",
        "            self.board_display,\n",
        "            self.game_controls,\n",
        "            self.audio_controls,\n",
        "            self.upload_status,\n",
        "            self.speech_status\n",
        "        ], layout=widgets.Layout(width='100%', align_items='center'))\n",
        "\n",
        "        # Display the UI\n",
        "        display(self.app)\n",
        "        \n",
        "        # Add JavaScript for text-to-speech functionality\n",
        "        display(HTML(\"\"\"\n",
        "        <script>\n",
        "        function speakText(text) {\n",
        "            if ('speechSynthesis' in window) {\n",
        "                const utterance = new SpeechSynthesisUtterance(text);\n",
        "                utterance.rate = 1.0;  // Speech rate\n",
        "                utterance.pitch = 1.0; // Speech pitch\n",
        "                window.speechSynthesis.cancel(); // Cancel any ongoing speech\n",
        "                window.speechSynthesis.speak(utterance);\n",
        "                return \"Speaking...\";\n",
        "            } else {\n",
        "                return \"Text-to-speech not supported in this browser.\";\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        // Make the function available to Python\n",
        "        window.speakText = speakText;\n",
        "        </script>\n",
        "        \"\"\"))\n",
        "\n",
        "    def read_board_aloud(self, _=None):\n",
        "        \"\"\"Convert board state to spoken text and read it aloud\"\"\"\n",
        "        board_text = self.generate_board_description()\n",
        "        \n",
        "        # Use JavaScript to speak the text\n",
        "        js_code = f\"\"\"\n",
        "        var result = \"\";\n",
        "        if (typeof window.speakText === 'function') {{\n",
        "            result = window.speakText(\"{board_text}\");\n",
        "        }} else {{\n",
        "            result = \"Text-to-speech function not available.\";\n",
        "        }}\n",
        "        result;\n",
        "        \"\"\"\n",
        "        \n",
        "        # Execute the JavaScript to speak the text\n",
        "        try:\n",
        "            from IPython.display import Javascript\n",
        "            display(Javascript(js_code))\n",
        "            self.speech_status.value = \"<p>Reading board state aloud...</p>\"\n",
        "            \n",
        "            # Clear the status after 3 seconds\n",
        "            def clear_status():\n",
        "                time.sleep(3)\n",
        "                self.speech_status.value = \"\"\n",
        "            \n",
        "            import threading\n",
        "            threading.Thread(target=clear_status).start()\n",
        "            \n",
        "        except Exception as e:\n",
        "            self.speech_status.value = f\"<p style='color:red;'>Error with text-to-speech: {str(e)}</p>\"\n",
        "\n",
        "    def generate_board_description(self):\n",
        "        \"\"\"Generate a textual description of the board state\"\"\"\n",
        "        # Get the board from state\n",
        "        board = self.state[\"board\"]\n",
        "        rows, cols = board.shape\n",
        "        \n",
        "        # Start with the game status\n",
        "        if hasattr(self, 'done') and self.done:\n",
        "            if self._check_winner(1):\n",
        "                winner = 1\n",
        "            elif self._check_winner(-1):\n",
        "                winner = -1\n",
        "            else:\n",
        "                winner = 0\n",
        "                \n",
        "            if winner == 1:\n",
        "                status = \"Player X has won. \" if self.ai_player == -1 else \"AI has won. \"\n",
        "            elif winner == -1:\n",
        "                status = \"AI has won. \" if self.ai_player == -1 else \"Player X has won. \"\n",
        "            else:\n",
        "                status = \"The game is a draw. \"\n",
        "        else:\n",
        "            human_player = -self.ai_player\n",
        "            if self.env.current_player == human_player:\n",
        "                player_name = \"Your\"\n",
        "                player_symbol = \"X\" if human_player == 1 else \"O\"\n",
        "            else:\n",
        "                player_name = \"AI's\"\n",
        "                player_symbol = \"X\" if self.ai_player == 1 else \"O\"\n",
        "                \n",
        "            status = f\"It is {player_name} turn with {player_symbol}. \"\n",
        "        \n",
        "        # Describe the board\n",
        "        board_desc = \"Board state: \"\n",
        "        \n",
        "        # Count pieces by column\n",
        "        for col in range(cols):\n",
        "            pieces = []\n",
        "            for row in range(rows-1, -1, -1):  # Start from bottom row\n",
        "                if board[row, col] == 1:\n",
        "                    pieces.append(\"X\")\n",
        "                elif board[row, col] == -1:\n",
        "                    pieces.append(\"O\")\n",
        "            \n",
        "            if pieces:\n",
        "                board_desc += f\"Column {col} has {len(pieces)} pieces: {', '.join(pieces)} from bottom to top. \"\n",
        "            else:\n",
        "                board_desc += f\"Column {col} is empty. \"\n",
        "        \n",
        "        # Escape quotes and special characters\n",
        "        full_description = status + board_desc\n",
        "        full_description = full_description.replace('\"', '\\\\\"').replace(\"'\", \"\\\\'\")\n",
        "        \n",
        "        return full_description\n",
        "\n",
        "    def handle_file_upload(self, change):\n",
        "        \"\"\"Handle file upload event\"\"\"\n",
        "        if change['new']:\n",
        "            try:\n",
        "                # Check if change['new'] is a tuple or a dictionary\n",
        "                if isinstance(change['new'], tuple):\n",
        "                    # If it's a tuple, extract the first element\n",
        "                    uploaded_file = change['new'][0]\n",
        "                else:\n",
        "                    # If it's a dictionary, use the original code\n",
        "                    uploaded_file = next(iter(change['new'].values()))\n",
        "                \n",
        "                # Check if 'metadata' exists in the structure\n",
        "                if 'metadata' in uploaded_file and 'name' in uploaded_file['metadata']:\n",
        "                    filename = uploaded_file['metadata']['name']\n",
        "                    # Just acknowledge the upload\n",
        "                    self.upload_status.value = f\"<p>File uploaded: {filename}</p>\"\n",
        "                else:\n",
        "                    # Handle case where metadata or name is missing\n",
        "                    self.upload_status.value = f\"<p>File uploaded successfully</p>\"\n",
        "                \n",
        "                self.upload_status.value += f\"<p>Click 'Process Command' to execute the command.</p>\"\n",
        "            except Exception as e:\n",
        "                # Fallback for any unexpected structure\n",
        "                self.upload_status.value = f\"<p>File uploaded, but couldn't read file details: {str(e)}</p>\"\n",
        "                self.upload_status.value += f\"<p>Click 'Process Command' to execute the command.</p>\"\n",
        "\n",
        "    def process_audio_command(self, _=None):\n",
        "        \"\"\"Process an uploaded audio file and dispatch the spoken command.\"\"\"\n",
        "        try:\n",
        "            # ── 1. Validate upload ────────────────────────────────────────────────\n",
        "            if not self.file_upload.value:\n",
        "                self.upload_status.value = (\n",
        "                    \"<p style='color:orange;'>Please upload an audio file first.</p>\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            try:\n",
        "                # Check if file_upload.value is a tuple or a dictionary\n",
        "                if isinstance(self.file_upload.value, tuple):\n",
        "                    # If it's a tuple, extract the first element\n",
        "                    uploaded = self.file_upload.value[0]\n",
        "                else:\n",
        "                    # If it's a dictionary, use the original code\n",
        "                    uploaded = next(iter(self.file_upload.value.values()))\n",
        "                \n",
        "                # Check if 'content' exists\n",
        "                if 'content' not in uploaded:\n",
        "                    self.upload_status.value = (\n",
        "                        \"<p style='color:red;'>Invalid file format: missing content</p>\"\n",
        "                    )\n",
        "                    return\n",
        "                    \n",
        "                raw_bytes = uploaded[\"content\"]\n",
        "                \n",
        "                # Try to get filename but provide default if not available\n",
        "                fname = \"uploaded_audio\"\n",
        "                if 'metadata' in uploaded and 'name' in uploaded['metadata']:\n",
        "                    fname = uploaded['metadata']['name']\n",
        "            except Exception as e:\n",
        "                self.upload_status.value = (\n",
        "                    f\"<p style='color:red;'>Error reading file: {str(e)}</p>\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            self.upload_status.value = \"<p style='color:blue;'>Processing audio file...</p>\"\n",
        "\n",
        "            # You need to import these libraries in your notebook\n",
        "            # If these imports are failing, install the libraries first:\n",
        "            # !pip install SpeechRecognition pydub\n",
        "            try:\n",
        "                import speech_recognition as sr\n",
        "                from pydub import AudioSegment\n",
        "            except ImportError as e:\n",
        "                self.upload_status.value = (\n",
        "                    \"<p style='color:red;'>Missing required Python libraries. Please run the following in a cell:</p>\"\n",
        "                    \"<pre>!pip install SpeechRecognition pydub</pre>\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            # ── 2. Convert to mono-WAV in-memory (handles mp3, wav, m4a, etc.) ────\n",
        "            try:\n",
        "                # This will fail if ffmpeg/ffprobe is not installed\n",
        "                audio = AudioSegment.from_file(io.BytesIO(raw_bytes))\n",
        "                audio = audio.set_frame_rate(16_000).set_channels(1)\n",
        "                with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as wav_tmp:\n",
        "                    audio.export(wav_tmp.name, format=\"wav\")\n",
        "                    wav_path = wav_tmp.name\n",
        "            except FileNotFoundError as err:\n",
        "                if 'ffprobe' in str(err) or 'ffmpeg' in str(err):\n",
        "                    self.upload_status.value = (\n",
        "                        \"<p style='color:red;'>Missing FFmpeg tools. This feature requires FFmpeg to be installed.</p>\"\n",
        "                        \"<p>Please install FFmpeg by running the following command in a cell:</p>\"\n",
        "                        \"<pre>!apt-get update && apt-get install -y ffmpeg</pre>\"\n",
        "                        \"<p>If using Google Colab, run:</p>\"\n",
        "                        \"<pre>!apt-get update && apt-get install -y ffmpeg</pre>\"\n",
        "                        \"<p>If using a local environment, install FFmpeg using your package manager, e.g.:</p>\"\n",
        "                        \"<p>- Ubuntu/Debian: <code>sudo apt install ffmpeg</code></p>\"\n",
        "                        \"<p>- macOS: <code>brew install ffmpeg</code></p>\"\n",
        "                        \"<p>- Windows: <a href='https://ffmpeg.org/download.html'>Download from ffmpeg.org</a></p>\"\n",
        "                    )\n",
        "                else:\n",
        "                    self.upload_status.value = (\n",
        "                        f\"<p style='color:red;'>Error: {str(err)}</p>\"\n",
        "                    )\n",
        "                return\n",
        "            except Exception as exc:\n",
        "                self.upload_status.value = (\n",
        "                    \"<p style='color:red;'>Cannot process audio \\\"\" + fname + \"\\\": \" + str(exc) + \"</p>\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            # ── 3. Speech-to-text (Google Web API) ────────────────────────────────\n",
        "            try:\n",
        "                recog = sr.Recognizer()\n",
        "                with sr.AudioFile(wav_path) as source:\n",
        "                    # remove ambient-noise adjustment for prerecorded files\n",
        "                    audio_data = recog.record(source)      # grab the whole file\n",
        "                text = recog.recognize_google(audio_data, language='en-US').lower()\n",
        "                self.upload_status.value = f\"<p>Heard: \\\"{text}\\\"</p>\"\n",
        "            except sr.UnknownValueError:\n",
        "                self.upload_status.value = (\n",
        "                    \"<p style='color:red;'>Sorry, I couldn't understand that.</p>\"\n",
        "                )\n",
        "                return\n",
        "            except sr.RequestError as exc:\n",
        "                self.upload_status.value = (\n",
        "                    \"<p style='color:red;'>Speech-service error: \" + str(exc) + \"</p>\"\n",
        "                )\n",
        "                return\n",
        "            finally:\n",
        "                # Clean temp file\n",
        "                with suppress(FileNotFoundError):\n",
        "                    os.remove(wav_path)\n",
        "\n",
        "            # ── 4. Command routing ────────────────────────────────────────────────\n",
        "            digit_words = {\n",
        "                \"zero\": 0,\n",
        "                \"one\": 1,\n",
        "                \"two\": 2,\n",
        "                \"three\": 3,\n",
        "                \"four\": 4,\n",
        "                \"five\": 5,\n",
        "                \"six\": 6,\n",
        "            }\n",
        "\n",
        "            # Add handling for \"read board\" command\n",
        "            if re.search(r\"\\bread\\b.*\\bboard\\b\", text):\n",
        "                self.upload_status.value += \"<p>Reading board state...</p>\"\n",
        "                self.read_board_aloud(None)\n",
        "                return\n",
        "\n",
        "            # new-game\n",
        "            if re.search(r\"\\bnew\\b.*\\bgame\\b\", text):\n",
        "                self.upload_status.value += \"<p>Starting a new game!</p>\"\n",
        "                self.start_new_game(None)\n",
        "                return\n",
        "\n",
        "            # column n / just n\n",
        "            # 1️⃣ match \"column three\", \"col 3\", \"place in five\" …\n",
        "            col_match = re.search(r\"\\b(col(?:umn)?|place(?:\\sin)?)\\s*(\\w+)\", text)\n",
        "            word_or_digit = None\n",
        "            if col_match:\n",
        "                word_or_digit = col_match.group(2)\n",
        "            else:\n",
        "                # 2️⃣ plain \"three\" / \"3\"\n",
        "                word_or_digit = text.strip()\n",
        "\n",
        "            # map to integer 0-6\n",
        "            if word_or_digit in digit_words:\n",
        "                col = digit_words[word_or_digit]\n",
        "            elif word_or_digit.isdigit() and 0 <= int(word_or_digit) <= 6:\n",
        "                col = int(word_or_digit)\n",
        "            else:\n",
        "                self.upload_status.value += (\n",
        "                    \"<p style='color:orange;'>Command not recognized. \"\n",
        "                    \"Say e.g. \\\"column three\\\", \\\"new game\\\", or \\\"read board\\\".</p>\"\n",
        "                )\n",
        "                return\n",
        "\n",
        "            # ── 5. Execute move ───────────────────────────────────────────────────\n",
        "            self.upload_status.value += f\"<p>Placing piece in column {col}</p>\"\n",
        "            self.make_move(col)\n",
        "\n",
        "            # ── 6. Reset uploader for next use ────────────────────────────────────\n",
        "            try:\n",
        "                if isinstance(self.file_upload.value, tuple):\n",
        "                    self.file_upload.value = ()  # Clear tuple\n",
        "                else:\n",
        "                    self.file_upload.value.clear()  # Clear dictionary\n",
        "            except Exception as e:\n",
        "                # Just ignore errors in clearing\n",
        "                pass\n",
        "\n",
        "        except ImportError as e:\n",
        "            self.upload_status.value = (\n",
        "                \"<p style='color:red;'>Missing required libraries: \" + str(e) + \". \"\n",
        "                \"Please install the required libraries using !pip install.</p>\"\n",
        "            )\n",
        "        except Exception as e:\n",
        "            self.upload_status.value = (\n",
        "                \"<p style='color:red;'>Error processing audio: \" + str(e) + \"</p>\"\n",
        "            )\n",
        "\n",
        "    def start_new_game(self, b):\n",
        "        \"\"\"Start a new game with the selected starting player\"\"\"\n",
        "        # Get who starts from the radio buttons\n",
        "        selected_value = self.player_starter.value\n",
        "\n",
        "        # Figure out who the AI player is based on selected value\n",
        "        self.ai_player = -selected_value\n",
        "        \n",
        "        # Assign the right model based on which player the AI is\n",
        "        self.model = self.model_p2 if self.ai_player == -1 else self.model_p1\n",
        "        \n",
        "        # Reset the game\n",
        "        self.state = self.env.reset()\n",
        "        self.done = False\n",
        "\n",
        "        # Re-enable buttons\n",
        "        for btn in self.buttons:\n",
        "            btn.disabled = False\n",
        "\n",
        "        # Update the display\n",
        "        self.update_display()\n",
        "\n",
        "        # If AI goes first, make its move\n",
        "        if self.env.current_player == self.ai_player:\n",
        "            time.sleep(0.5)\n",
        "            self.make_ai_move()\n",
        "\n",
        "    def render_board_html(self):\n",
        "        \"\"\"Render the Connect 4 board as HTML for display\"\"\"\n",
        "        html = \"\"\"\n",
        "        <style>\n",
        "        .board {\n",
        "            background-color: #0052cc;\n",
        "            display: inline-block;\n",
        "            padding: 10px;\n",
        "            border-radius: 10px;\n",
        "        }\n",
        "        .cell {\n",
        "            width: 60px;\n",
        "            height: 60px;\n",
        "            background-color: #ffffff;\n",
        "            border-radius: 50%;\n",
        "            display: inline-block;\n",
        "            margin: 5px;\n",
        "        }\n",
        "        .player1 {\n",
        "            background-color: #ff0000;\n",
        "        }\n",
        "        .player-1 {\n",
        "            background-color: #ffff00;\n",
        "        }\n",
        "        </style>\n",
        "        <div class=\"board\">\n",
        "        \"\"\"\n",
        "\n",
        "        # Get board from state\n",
        "        board = self.state[\"board\"]\n",
        "        rows, cols = board.shape\n",
        "        \n",
        "        for row in range(rows):\n",
        "            html += \"<div>\"\n",
        "            for col in range(cols):\n",
        "                cell_value = board[row, col]\n",
        "                cell_class = f\"cell player{cell_value}\" if cell_value != 0 else \"cell\"\n",
        "                html += f'<div class=\"{cell_class}\"></div>'\n",
        "            html += \"</div>\"\n",
        "\n",
        "        html += \"</div>\"\n",
        "        return html\n",
        "\n",
        "    def update_display(self):\n",
        "        \"\"\"Update the board display and status message\"\"\"\n",
        "        self.board_display.value = self.render_board_html()\n",
        "\n",
        "        # Check game status\n",
        "        if hasattr(self, 'done') and self.done:\n",
        "            # Game is over\n",
        "            if self._check_winner(1):\n",
        "                winner = 1\n",
        "            elif self._check_winner(-1):\n",
        "                winner = -1\n",
        "            else:\n",
        "                winner = 0  # Draw\n",
        "\n",
        "            if winner == 1:\n",
        "                message = \"You win! 🎉\" if self.ai_player == -1 else \"AI wins! 🤖\"\n",
        "                color = \"green\" if self.ai_player == -1 else \"red\"\n",
        "            elif winner == -1:\n",
        "                message = \"AI wins! 🤖\" if self.ai_player == -1 else \"You win! 🎉\"\n",
        "                color = \"red\" if self.ai_player == -1 else \"green\"\n",
        "            else:\n",
        "                message = \"Draw game! 🤝\"\n",
        "                color = \"blue\"\n",
        "\n",
        "            self.status.value = f\"<h3 style='text-align: center; color: {color};'>{message}</h3>\"\n",
        "\n",
        "            # Disable column buttons\n",
        "            for btn in self.buttons:\n",
        "                btn.disabled = True\n",
        "        else:\n",
        "            # Game is ongoing\n",
        "            current_player = self.env.current_player\n",
        "            human_player = -self.ai_player\n",
        "\n",
        "            if current_player == human_player:\n",
        "                player_name = \"Your\"\n",
        "                player_symbol = \"(X)\" if human_player == 1 else \"(O)\"\n",
        "            else:\n",
        "                player_name = \"AI's\"\n",
        "                player_symbol = \"(X)\" if self.ai_player == 1 else \"(O)\"\n",
        "\n",
        "            self.status.value = f\"<h3 style='text-align: center;'>{player_name} turn {player_symbol}</h3>\"\n",
        "\n",
        "    def valid_actions(self):\n",
        "        \"\"\"Helper method to get valid actions from BoardEnv\"\"\"\n",
        "        # Add this method to simulate the Connect4Env's valid_actions method\n",
        "        return [c for c in range(7) if self.env._is_valid_action(c)]\n",
        "\n",
        "    def make_move(self, column):\n",
        "        \"\"\"Handle player's move on column click\"\"\"\n",
        "        if hasattr(self, 'done') and self.done:\n",
        "            # Game is already over\n",
        "            return\n",
        "\n",
        "        # Determine if it's human's turn\n",
        "        human_player = -self.ai_player\n",
        "        if self.env.current_player != human_player:\n",
        "            self.status.value = \"<h3 style='text-align: center; color: orange;'>Not your turn!</h3>\"\n",
        "            return\n",
        "\n",
        "        # Check if move is valid\n",
        "        if not self.env._is_valid_action(column):  # Changed from valid_actions to _is_valid_action\n",
        "            self.status.value = \"<h3 style='text-align: center; color: orange;'>Invalid move! Column is full</h3>\"\n",
        "            return\n",
        "\n",
        "        # Make the move\n",
        "        next_state, reward, done, _ = self.env.step(column)\n",
        "        self.state = next_state\n",
        "        self.done = done\n",
        "\n",
        "        # Update the display\n",
        "        self.update_display()\n",
        "\n",
        "        # If game not over and AI's turn, make AI move\n",
        "        if not done and self.env.current_player == self.ai_player:\n",
        "            # Add a small delay for better UX\n",
        "            time.sleep(0.5)\n",
        "            self.make_ai_move()\n",
        "\n",
        "    def make_ai_move(self):\n",
        "        \"\"\"Make an AI move using the model\"\"\"\n",
        "        if hasattr(self, 'done') and self.done:\n",
        "            return\n",
        "\n",
        "        # Use the model to select an action\n",
        "        # Prepare tensor\n",
        "        state_tensor = torch.tensor(self.state[\"board\"], dtype=torch.float32, device=device).unsqueeze(0).unsqueeze(0)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            qvals = self.model(state_tensor)\n",
        "            # Mask out illegal moves\n",
        "            illegal_mask = get_illegal_moves_mask(self.state[\"board\"])\n",
        "            qvals[0][illegal_mask] = -1e9\n",
        "            action = qvals.argmax(dim=1).item()\n",
        "\n",
        "        # Make the move\n",
        "        next_state, reward, done, _ = self.env.step(action)\n",
        "        self.state = next_state\n",
        "        self.done = done\n",
        "\n",
        "        # Update the display\n",
        "        self.update_display() \n",
        "\n",
        "    def _check_winner(self, player):\n",
        "        \"\"\"Check if given player has won by having 4 in a row anywhere on the board\"\"\"\n",
        "        # Can only win if player is 1 (X) or -1 (O)\n",
        "        if player == 0:\n",
        "            return False\n",
        "            \n",
        "        board = self.state[\"board\"]  # Use self.state[\"board\"] instead of self.env.state[\"board\"]\n",
        "        rows, cols = board.shape\n",
        "    \n",
        "        # Horizontal check\n",
        "        for r in range(rows):\n",
        "            for c in range(cols - 3):\n",
        "                if (board[r, c] == player and \n",
        "                    board[r, c+1] == player and \n",
        "                    board[r, c+2] == player and \n",
        "                    board[r, c+3] == player):\n",
        "                    return True\n",
        "        \n",
        "        # Vertical check\n",
        "        for r in range(rows - 3):\n",
        "            for c in range(cols):\n",
        "                if (board[r, c] == player and \n",
        "                    board[r+1, c] == player and \n",
        "                    board[r+2, c] == player and \n",
        "                    board[r+3, c] == player):\n",
        "                    return True\n",
        "        \n",
        "        # Diagonal down-right\n",
        "        for r in range(rows - 3):\n",
        "            for c in range(cols - 3):\n",
        "                if (board[r, c] == player and \n",
        "                    board[r+1, c+1] == player and \n",
        "                    board[r+2, c+2] == player and \n",
        "                    board[r+3, c+3] == player):\n",
        "                    return True\n",
        "        \n",
        "        # Diagonal up-right\n",
        "        for r in range(3, rows):\n",
        "            for c in range(cols - 3):\n",
        "                if (board[r, c] == player and \n",
        "                    board[r-1, c+1] == player and \n",
        "                    board[r-2, c+2] == player and \n",
        "                    board[r-3, c+3] == player):\n",
        "                    return True\n",
        "        \n",
        "        return False\n",
        "\n",
        "def start_connect4_ui(model_p1, model_p2, ai_player=-1):\n",
        "    \"\"\"\n",
        "    Start the Connect4 UI with the trained models\n",
        "\n",
        "    Args:\n",
        "        model_p1: The trained DQN model for player 1\n",
        "        model_p2: The trained DQN model for player 2\n",
        "        ai_player: The player ID for the AI (-1 or 1)\n",
        "    \"\"\"\n",
        "    ui = Connect4UI(model_p1, model_p2, ai_player=ai_player)\n",
        "    return ui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Metrics (WE NEED TO MODIFY THE PATH WE LOAD FROM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Play (WE NEED TO MODIFY THE PATH WE LOAD FROM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/4d/yh24l07s0v7gm5xwwh_dr0mh0000gn/T/ipykernel_55218/2217014503.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_p1.load_state_dict(torch.load(\"checkpoints/c4_dqn_20250511_143151/policy_net1_ep0500.pth\", map_location=device))\n",
            "/var/folders/4d/yh24l07s0v7gm5xwwh_dr0mh0000gn/T/ipykernel_55218/2217014503.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_p2.load_state_dict(torch.load(\"checkpoints/c4_dqn_20250511_143151/policy_net2_ep0500.pth\", map_location=device))\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92cbf9f30e0a448f93413bc96a5ca658",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value=\"<h1 style='text-align: center;'>Connect 4</h1>\"), HTML(value=\"<h3 style='text-align…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "        <script>\n",
              "        function speakText(text) {\n",
              "            if ('speechSynthesis' in window) {\n",
              "                const utterance = new SpeechSynthesisUtterance(text);\n",
              "                utterance.rate = 1.0;  // Speech rate\n",
              "                utterance.pitch = 1.0; // Speech pitch\n",
              "                window.speechSynthesis.cancel(); // Cancel any ongoing speech\n",
              "                window.speechSynthesis.speak(utterance);\n",
              "                return \"Speaking...\";\n",
              "            } else {\n",
              "                return \"Text-to-speech not supported in this browser.\";\n",
              "            }\n",
              "        }\n",
              "        \n",
              "        // Make the function available to Python\n",
              "        window.speakText = speakText;\n",
              "        </script>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n        var result = \"\";\n        if (typeof window.speakText === 'function') {\n            result = window.speakText(\"It is Your turn with X. Board state: Column 0 is empty. Column 1 is empty. Column 2 is empty. Column 3 is empty. Column 4 is empty. Column 5 is empty. Column 6 is empty. \");\n        } else {\n            result = \"Text-to-speech function not available.\";\n        }\n        result;\n        ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def start_connect4_ui(model_p1, model_p2, ai_player=-1):\n",
        "    \"\"\"\n",
        "    Start the Connect4 UI with the trained models\n",
        "\n",
        "    Args:\n",
        "        model_p1: The trained DQN model for player 1\n",
        "        model_p2: The trained DQN model for player 2\n",
        "        ai_player: The player ID for the AI (-1 or 1)\n",
        "    \"\"\"\n",
        "    ui = Connect4UI(model_p1, model_p2, ai_player=ai_player)\n",
        "    return ui\n",
        "\n",
        "# Load your trained models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_p1 = ConvQNetwork(input_shape=(1,6,7), num_actions=7).to(device)\n",
        "model_p2 = ConvQNetwork(input_shape=(1,6,7), num_actions=7).to(device)\n",
        "\n",
        "# Load saved model weights\n",
        "model_p1.load_state_dict(torch.load(\"checkpoints/c4_dqn_20250511_143151/policy_net1_ep0500.pth\", map_location=device))\n",
        "model_p2.load_state_dict(torch.load(\"checkpoints/c4_dqn_20250511_143151/policy_net2_ep0500.pth\", map_location=device))\n",
        "\n",
        "# Set models to evaluation mode\n",
        "model_p1.eval()\n",
        "model_p2.eval()\n",
        "\n",
        "ui = start_connect4_ui(model_p1, model_p2, ai_player=-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWiM-FmemwKR"
      },
      "source": [
        "## 6. Extensions and Next Steps\n",
        "\n",
        "- Define a real environment and replace the placeholder reward function.\n",
        "- Implement action selection strategies (epsilon-greedy, softmax).  \n",
        "- Add saving/loading model checkpoints.  \n",
        "- Incorporate advanced techniques: Double DQN, Prioritized Experience Replay, Dueling Networks.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "research_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
